{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import random as rand\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import normalize, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux-4.4.0-1112-aws-x86_64-with-debian-stretch-sid\n",
      "NumPy 1.14.3\n",
      "SciPy 1.1.0\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import scipy\n",
    "import sklearn\n",
    "print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n",
    "print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class ObfuscationTransformer(BaseEstimator):\n",
    "    def __init__(self,re_from=r'(\\b)(\\w{0,2})\\w+(\\w{1,3})(\\b)', re_to=r'\\1\\2XX\\3\\4', return_copy=True):\n",
    "        self.re_from = re_from\n",
    "        self.re_to = re_to\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.array(X).copy();\n",
    "        for i in range(len(X)):\n",
    "            X[i] = re.sub(self.re_from,self.re_to, X[i])\n",
    "        \n",
    "        return X;\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gt,\n",
    "                  pred)\n",
    "\n",
    "    return f1,precision,recall,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineCharacter = Pipeline([\n",
    "    ('vect',   TfidfVectorizer(\n",
    "            analyzer='char',\n",
    "            min_df=0.05,\n",
    "            max_df=1.0,\n",
    "            ngram_range=(2,5),\n",
    "            lowercase=False,\n",
    "            norm='l2',\n",
    "            sublinear_tf=True)),\n",
    "    ('dense',  DenseTransformer()),\n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    ('transf', PCA(0.999)),\n",
    "    ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "])\n",
    "\n",
    "pipelineObfuscator = Pipeline([\n",
    "        ('obs',ObfuscationTransformer(re_from=r'\\w',re_to='x')),\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='char',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(2,5),\n",
    "                lowercase=False,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "\n",
    "pipelineWord = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='word',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(1,3),\n",
    "                lowercase=True,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')),\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "language = 'fr'\n",
    "\n",
    "corpus_type = 'tweets_' + language + '.csv'\n",
    "\n",
    "os.chdir('/home/ubuntu/lab/Experimentos/experimento_3_twisty')\n",
    "df = pd.read_csv('input/' + corpus_type, sep=';', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'author': 'id_author'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_count = df.groupby('id_author').size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['gender'] = np.where(df['gender']=='M', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['id_author'] = df['filename'].str.split('.', expand=True)[0]\n",
    "#del df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['count_delimiter'] = df['text'].str.split(\"\\|<->\\|\").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_statistics = df.copy()\n",
    "df_final_statistics['number_of_words'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de unidades: 1044604\n",
      "Total de palavras: 14002319\n",
      "Total de palavras/unidade: 13.404427898036003\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de unidades: \" + str(len(df_final_statistics)))\n",
    "print(\"Total de palavras: \" + str(sum(df_final_statistics['number_of_words'])))\n",
    "print(\"Total de palavras/unidade: \" + str(sum(df_final_statistics['number_of_words'])/len(df_final_statistics)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selecao de autores com mais textos\n",
    "limit_authors_aa_selection = 20\n",
    "#list_authors_aa_selection = list(df_final['id_author'].value_counts()[:limit_authors_aa_selection].index)\n",
    "list_authors_aa_selection = list(df_count.sort_values(by='counts', ascending=False)[:limit_authors_aa_selection]['id_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisao de bases\n",
    "df_aa = df[df['id_author'].isin(list_authors_aa_selection)]\n",
    "df_ca = df[~df['id_author'].isin(list_authors_aa_selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_ca_group = df_ca.groupby(['id_author'])['text'].apply('|<->|'.join).reset_index()\n",
    "df_ca_group = df_ca_group.merge(df_ca[['id_author', 'gender']].drop_duplicates())\n",
    "\n",
    "df_aa_group = df_aa.groupby(['id_author'])['text'].apply('|<->|'.join).reset_index()\n",
    "df_aa_group = df_aa_group.merge(df_aa[['id_author', 'gender']].drop_duplicates())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca = df_ca_group\n",
    "df_aa = df_aa_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kbest = Pipeline([\n",
    "    ('vect', TfidfVectorizer()), \n",
    "    ('k_best', SelectKBest(f_classif)),\n",
    "    ('clf', LogisticRegression(random_state=42, n_jobs=6))\n",
    "])\n",
    "    \n",
    "parameters_kbest = {    \n",
    "    'k_best__k': (range(3000,20000,1000))\n",
    "}\n",
    "\n",
    "grid_search_resp = GridSearchCV(pipeline_kbest,\n",
    "                               parameters_kbest,\n",
    "                               cv=10,\n",
    "                               scoring='f1_macro',\n",
    "                               n_jobs=4,\n",
    "                               verbose=10\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list = ['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_best_dict = {}\n",
    "\n",
    "#for ca in ca_list:\n",
    "   \n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "#    grid_search_resp.fit(df_ca['text'], df_ca_group[ca])\n",
    "#    print('Finalizado, tarefa: ' + str(ca))\n",
    "\n",
    "#    k_best_dict.update({ca: grid_search_resp.best_estimator_.get_params()['k_best__k']})\n",
    "#print(k_best_dict)\n",
    "\n",
    "#### O resultado deste for é:\n",
    "#k_best_dict = { #'gender': 8000, ## ES,\n",
    "                #'gender': 8000, ## DE,\n",
    "                #'gender': 3000, ## IT,\n",
    "                #'gender': 6000, ## NL,\n",
    "                #'gender': 6000, ## PT,\n",
    "                #'gender': 19000, ## FR\n",
    "#}\n",
    "\n",
    "if language=='es':\n",
    "    k_best_dict = {'gender': 8000} ## ES\n",
    "if language=='de':\n",
    "    k_best_dict = {'gender': 8000} ## DE\n",
    "if language=='it':\n",
    "    k_best_dict = {'gender': 3000} ## IT\n",
    "if language=='nl':\n",
    "    k_best_dict = {'gender': 6000} ## NL\n",
    "if language=='pt':\n",
    "    k_best_dict = {'gender': 6000} ## PT\n",
    "if language=='fr':\n",
    "    k_best_dict = {'gender': 19000} ## FR\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': 19000}\n"
     ]
    }
   ],
   "source": [
    "print(k_best_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# estimado\n",
    "#k_best_dict = {'gender': 1800,\n",
    "#               'ap_age': 9800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_vectorized_train = vect.fit_transform(df_ca['text'])\n",
    "text_vectorized_test = vect.transform(df_aa['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = df_aa['id_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6364932</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8421442</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27342429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35814511</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>55523877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>76294960</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>113392228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>172903185</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>296921560</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>338349721</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>350855821</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>362429030</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>370023500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>474946988</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>480420853</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>515700796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>523093601</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>560459880</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>836185218</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>964556156</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id_author  gender\n",
       "0     6364932       1\n",
       "1     8421442       0\n",
       "2    27342429       1\n",
       "3    35814511       0\n",
       "4    55523877       1\n",
       "5    76294960       0\n",
       "6   113392228       0\n",
       "7   172903185       0\n",
       "8   296921560       0\n",
       "9   338349721       1\n",
       "10  350855821       0\n",
       "11  362429030       1\n",
       "12  370023500       0\n",
       "13  474946988       0\n",
       "14  480420853       1\n",
       "15  515700796       0\n",
       "16  523093601       0\n",
       "17  560459880       1\n",
       "18  836185218       0\n",
       "19  964556156       0"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_aa[['id_author', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#df_ca.head()\n",
    "#df_ca['text'].iloc[0]\n",
    "#df_ca.shape\n",
    "#df_ca['id_author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ca_var        f1  precision    recall  accuracy\n",
      "0  gender  0.435737   0.460784  0.479167      0.55\n"
     ]
    }
   ],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = list(df_aa['id_author'])\n",
    "\n",
    "#print('ca;accuracy;precision_macro;recall_macro;f1_macro')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "\n",
    "    k_best = k_best_dict[ca_var]\n",
    "    sel = SelectKBest(k = k_best)\n",
    "    ft = sel.fit(text_vectorized_train, df_ca[ca_var])\n",
    "    train_best = ft.transform(text_vectorized_train)\n",
    "\n",
    "    clf.fit(train_best, df_ca[ca_var])\n",
    "\n",
    "    test_best = ft.transform(text_vectorized_test)\n",
    "\n",
    "    predicted = clf.predict(test_best) #com variavel categorica\n",
    "    predicted_prob = clf.predict_proba(test_best) #com probabilidade de variavel\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_aa[ca_var], predicted)\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))\n",
    "\n",
    "    df_test_ca[ca_var + '_predict'] = predicted\n",
    "    \n",
    "    # probs\n",
    "    df_temp = pd.DataFrame(predicted_prob)\n",
    "    df_temp = df_temp.add_prefix(ca_var + '_')\n",
    "    df_test_ca = df_test_ca.join(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='stratified') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_stratified'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='most_frequent') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_most_frequent'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca_baseline.merge(df_aa[['id_author', 'gender']],\n",
    "                          left_on='id_author', right_on='id_author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ca_var     f1  precision  recall  accuracy\n",
      "0  gender  0.375        0.3     0.5       0.6\n"
     ]
    }
   ],
   "source": [
    "#baseline CA\n",
    "#print('ca;f1;precision_macro;recall_macro;accuracy')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_test_ca_baseline[ca_var], df_test_ca_baseline[ca_var + '_dummy_most_frequent'])\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final = df_aa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(df_aa)):\n",
    "    text_list = df_aa['text'].iloc[i].split('|<->|')\n",
    "    author_list = [df_aa['id_author'].iloc[i]]*len(text_list)\n",
    "    df_inter = pd.DataFrame(data=[text_list, author_list]).T\n",
    "    df_inter = df_inter.rename(columns={0: 'text', 1: 'id_author'})\n",
    "    \n",
    "    df_final = df_final.append(df_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['text'].apply(len)>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50606, 2)"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_aa = df_final[df_final['id_author'].isin(list_authors_aa_selection)]\n",
    "df_final_aa['id_author'] = df_final_aa['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca['id_author'] = df_test_ca['id_author'].astype(int)\n",
    "df['id_author'] = df['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_aa = df_final_aa.merge(df_test_ca, how='left', left_on='id_author', right_on='id_author')\n",
    "#df_final_aa = df_final_aa.merge(df[['id_author', 'gender']], how='left', left_on='id_author', right_on='id_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender_predict</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_dummy_stratified</th>\n",
       "      <th>gender_dummy_most_frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@alexvansteen bier is frisdrank, wijn is goden...</td>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@janroegiers veel plezier daar. mooie stad</td>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bedankt regen voor het fijne welkomstcomité hi...</td>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>valies uitpakken en een beetje acclimatiseren ...</td>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@pieternagels dank u, ik kijk uit naar onze we...</td>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id_author  \\\n",
       "0  @alexvansteen bier is frisdrank, wijn is goden...   12369212   \n",
       "1         @janroegiers veel plezier daar. mooie stad   12369212   \n",
       "2  bedankt regen voor het fijne welkomstcomité hi...   12369212   \n",
       "3  valies uitpakken en een beetje acclimatiseren ...   12369212   \n",
       "4  @pieternagels dank u, ik kijk uit naar onze we...   12369212   \n",
       "\n",
       "   gender_predict  gender_0  gender_1  gender_dummy_stratified  \\\n",
       "0               0  0.527632  0.472368                        0   \n",
       "1               0  0.527632  0.472368                        0   \n",
       "2               0  0.527632  0.472368                        0   \n",
       "3               0  0.527632  0.472368                        0   \n",
       "4               0  0.527632  0.472368                        0   \n",
       "\n",
       "   gender_dummy_most_frequent  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50606, 7)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_final_aa['id_author'].unique()\n",
    "df_final_aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender_predict</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_dummy_stratified</th>\n",
       "      <th>gender_dummy_most_frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12749932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528933</td>\n",
       "      <td>0.471067</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14141508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534758</td>\n",
       "      <td>0.465242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15280197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518255</td>\n",
       "      <td>0.481745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19082430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520016</td>\n",
       "      <td>0.479984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_author  gender_predict  gender_0  gender_1  gender_dummy_stratified  \\\n",
       "0   12369212               0  0.527632  0.472368                        0   \n",
       "1   12749932               0  0.528933  0.471067                        1   \n",
       "2   14141508               0  0.534758  0.465242                        1   \n",
       "3   15280197               0  0.518255  0.481745                        0   \n",
       "4   19082430               0  0.520016  0.479984                        1   \n",
       "\n",
       "   gender_dummy_most_frequent  \n",
       "0                           0  \n",
       "1                           0  \n",
       "2                           0  \n",
       "3                           0  \n",
       "4                           0  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_test_ca['id_author'].unique()\n",
    "df_test_ca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "scoring = ['accuracy','precision_macro', 'recall_macro', 'f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender_predict</th>\n",
       "      <th>gender_0</th>\n",
       "      <th>gender_1</th>\n",
       "      <th>gender_dummy_stratified</th>\n",
       "      <th>gender_dummy_most_frequent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@alexvansteen bier is frisdrank, wijn is goden...</td>\n",
       "      <td>12369212</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527632</td>\n",
       "      <td>0.472368</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2811</th>\n",
       "      <td>wat is een gebeurtenis die erg bepalend is gew...</td>\n",
       "      <td>12749932</td>\n",
       "      <td>0</td>\n",
       "      <td>0.528933</td>\n",
       "      <td>0.471067</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5204</th>\n",
       "      <td>leest:  'elke tweede verkochte auto is duits' ...</td>\n",
       "      <td>14141508</td>\n",
       "      <td>0</td>\n",
       "      <td>0.534758</td>\n",
       "      <td>0.465242</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7752</th>\n",
       "      <td>dus rt @josheymans: top van lansschot krijgt v...</td>\n",
       "      <td>15280197</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518255</td>\n",
       "      <td>0.481745</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10191</th>\n",
       "      <td>eerlijke bankwijzer over #triodos. veruit te v...</td>\n",
       "      <td>19082430</td>\n",
       "      <td>0</td>\n",
       "      <td>0.520016</td>\n",
       "      <td>0.479984</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12768</th>\n",
       "      <td>@levensdocument dankjewel, carolien voelt heel...</td>\n",
       "      <td>81581036</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530692</td>\n",
       "      <td>0.469308</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15301</th>\n",
       "      <td>was een gezellig avondje met @laisabje @larisj...</td>\n",
       "      <td>95502094</td>\n",
       "      <td>0</td>\n",
       "      <td>0.595105</td>\n",
       "      <td>0.404895</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17511</th>\n",
       "      <td>@robertmazier geen kwaad woord over kliederkerk</td>\n",
       "      <td>101546714</td>\n",
       "      <td>1</td>\n",
       "      <td>0.499577</td>\n",
       "      <td>0.500423</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19903</th>\n",
       "      <td>@luciahardonk @elsbethgruteke @joosthsmit de l...</td>\n",
       "      <td>103001137</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538818</td>\n",
       "      <td>0.461182</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22355</th>\n",
       "      <td>@silvanvijver ik ben er weer, dus jij mag zo b...</td>\n",
       "      <td>106374560</td>\n",
       "      <td>0</td>\n",
       "      <td>0.550053</td>\n",
       "      <td>0.449947</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24784</th>\n",
       "      <td>@ewoutlk misschien omdat je wel droog zit maar...</td>\n",
       "      <td>114692268</td>\n",
       "      <td>0</td>\n",
       "      <td>0.554476</td>\n",
       "      <td>0.445524</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27347</th>\n",
       "      <td>@peetje38 klopt. tegen het einde hield het op ...</td>\n",
       "      <td>115791621</td>\n",
       "      <td>0</td>\n",
       "      <td>0.527358</td>\n",
       "      <td>0.472642</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29838</th>\n",
       "      <td>jelle wordt spontaan ziek van opruimen en mama...</td>\n",
       "      <td>118997159</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562202</td>\n",
       "      <td>0.437798</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32688</th>\n",
       "      <td>@dekienehoef @kienehoef tot hoe laat is de sna...</td>\n",
       "      <td>126412278</td>\n",
       "      <td>0</td>\n",
       "      <td>0.530897</td>\n",
       "      <td>0.469103</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35409</th>\n",
       "      <td>oude tijden van arcadehallen herleven in het w...</td>\n",
       "      <td>138372443</td>\n",
       "      <td>1</td>\n",
       "      <td>0.484724</td>\n",
       "      <td>0.515276</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37801</th>\n",
       "      <td>@amandavis1990 luister naar mooie muziek of he...</td>\n",
       "      <td>138673886</td>\n",
       "      <td>0</td>\n",
       "      <td>0.504926</td>\n",
       "      <td>0.495074</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40379</th>\n",
       "      <td>met z'n tweetjes 2 daagjes in #amsterdam. dat ...</td>\n",
       "      <td>154890428</td>\n",
       "      <td>1</td>\n",
       "      <td>0.473485</td>\n",
       "      <td>0.526515</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42897</th>\n",
       "      <td>@mathijsbouman nederlands is de grootste netto...</td>\n",
       "      <td>183999696</td>\n",
       "      <td>0</td>\n",
       "      <td>0.518871</td>\n",
       "      <td>0.481129</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45423</th>\n",
       "      <td>nagellak #essie fifth avenue getest en fan. nu...</td>\n",
       "      <td>287347336</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573650</td>\n",
       "      <td>0.426350</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48263</th>\n",
       "      <td>@heidisteven ik snap het, vind het ook rot voo...</td>\n",
       "      <td>314677328</td>\n",
       "      <td>0</td>\n",
       "      <td>0.561245</td>\n",
       "      <td>0.438755</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  id_author  \\\n",
       "0      @alexvansteen bier is frisdrank, wijn is goden...   12369212   \n",
       "2811   wat is een gebeurtenis die erg bepalend is gew...   12749932   \n",
       "5204   leest:  'elke tweede verkochte auto is duits' ...   14141508   \n",
       "7752   dus rt @josheymans: top van lansschot krijgt v...   15280197   \n",
       "10191  eerlijke bankwijzer over #triodos. veruit te v...   19082430   \n",
       "12768  @levensdocument dankjewel, carolien voelt heel...   81581036   \n",
       "15301  was een gezellig avondje met @laisabje @larisj...   95502094   \n",
       "17511    @robertmazier geen kwaad woord over kliederkerk  101546714   \n",
       "19903  @luciahardonk @elsbethgruteke @joosthsmit de l...  103001137   \n",
       "22355  @silvanvijver ik ben er weer, dus jij mag zo b...  106374560   \n",
       "24784  @ewoutlk misschien omdat je wel droog zit maar...  114692268   \n",
       "27347  @peetje38 klopt. tegen het einde hield het op ...  115791621   \n",
       "29838  jelle wordt spontaan ziek van opruimen en mama...  118997159   \n",
       "32688  @dekienehoef @kienehoef tot hoe laat is de sna...  126412278   \n",
       "35409  oude tijden van arcadehallen herleven in het w...  138372443   \n",
       "37801  @amandavis1990 luister naar mooie muziek of he...  138673886   \n",
       "40379  met z'n tweetjes 2 daagjes in #amsterdam. dat ...  154890428   \n",
       "42897  @mathijsbouman nederlands is de grootste netto...  183999696   \n",
       "45423  nagellak #essie fifth avenue getest en fan. nu...  287347336   \n",
       "48263  @heidisteven ik snap het, vind het ook rot voo...  314677328   \n",
       "\n",
       "       gender_predict  gender_0  gender_1  gender_dummy_stratified  \\\n",
       "0                   0  0.527632  0.472368                        0   \n",
       "2811                0  0.528933  0.471067                        1   \n",
       "5204                0  0.534758  0.465242                        1   \n",
       "7752                0  0.518255  0.481745                        0   \n",
       "10191               0  0.520016  0.479984                        1   \n",
       "12768               0  0.530692  0.469308                        1   \n",
       "15301               0  0.595105  0.404895                        1   \n",
       "17511               1  0.499577  0.500423                        1   \n",
       "19903               0  0.538818  0.461182                        0   \n",
       "22355               0  0.550053  0.449947                        1   \n",
       "24784               0  0.554476  0.445524                        0   \n",
       "27347               0  0.527358  0.472642                        1   \n",
       "29838               0  0.562202  0.437798                        1   \n",
       "32688               0  0.530897  0.469103                        0   \n",
       "35409               1  0.484724  0.515276                        1   \n",
       "37801               0  0.504926  0.495074                        1   \n",
       "40379               1  0.473485  0.526515                        1   \n",
       "42897               0  0.518871  0.481129                        0   \n",
       "45423               0  0.573650  0.426350                        1   \n",
       "48263               0  0.561245  0.438755                        1   \n",
       "\n",
       "       gender_dummy_most_frequent  \n",
       "0                               0  \n",
       "2811                            0  \n",
       "5204                            0  \n",
       "7752                            0  \n",
       "10191                           0  \n",
       "12768                           0  \n",
       "15301                           0  \n",
       "17511                           0  \n",
       "19903                           0  \n",
       "22355                           0  \n",
       "24784                           0  \n",
       "27347                           0  \n",
       "29838                           0  \n",
       "32688                           0  \n",
       "35409                           0  \n",
       "37801                           0  \n",
       "40379                           0  \n",
       "42897                           0  \n",
       "45423                           0  \n",
       "48263                           0  "
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.drop_duplicates(subset=['id_author'])\n",
    "#[['id_author', 'gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(df_train, author, simulation, ca_list, author_list):\n",
    "    ### train\n",
    "    try:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_train[['text'] + ca_list], \n",
    "                                                        df_train['id_author'], \n",
    "                                                    test_size=0.3,random_state=rand.randint(0,900))\n",
    "\n",
    "        pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "        for p in pipelines:\n",
    "            p.fit(x_train['text'], y_train)\n",
    "\n",
    "        predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "        df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "        if 'gender_0' in x_train.columns:\n",
    "            df_train_mix['gender_0'] = x_train['gender_0'].values\n",
    "        if 'gender_1' in x_train.columns:\n",
    "            df_train_mix['gender_1'] = x_train['gender_1'].values\n",
    "        if 'ap_age_0' in x_train.columns:\n",
    "            df_train_mix['ap_age_0'] = x_train['ap_age_0'].values\n",
    "        if 'ap_age_1' in x_train.columns:\n",
    "            df_train_mix['ap_age_1'] = x_train['ap_age_1'].values\n",
    "        if 'ap_age_2' in x_train.columns:\n",
    "            df_train_mix['ap_age_2'] = x_train['ap_age_2'].values\n",
    "\n",
    "        if 'gender' in x_train.columns:\n",
    "            df_train_mix['gender'] = x_train['gender'].values\n",
    "        if 'ap_age' in x_train.columns:\n",
    "            df_train_mix['ap_age'] = x_train['ap_age'].values\n",
    "            \n",
    "        if 'gender_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['gender_dummy_most_frequent'] = x_train['gender_dummy_most_frequent'].values\n",
    "        if 'ap_age_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['ap_age_dummy_most_frequent'] = x_train['ap_age_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['gender_dummy_stratified'] = x_train['gender_dummy_stratified'].values\n",
    "        if 'ap_age_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['ap_age_dummy_stratified'] = x_train['ap_age_dummy_stratified'].values\n",
    "            \n",
    "        if 'gender_predict' in x_train.columns:\n",
    "            df_train_mix['gender_predict'] = x_train['gender_predict'].values\n",
    "        if 'ap_age_predict' in x_train.columns:\n",
    "            df_train_mix['ap_age_predict'] = x_train['ap_age_predict'].values\n",
    "\n",
    "        clf_final.fit(df_train_mix, y_train)\n",
    "\n",
    "        #test\n",
    "        predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "        df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "        if 'gender_0' in x_test.columns:\n",
    "            df_test_mix['gender_0'] = x_test['gender_0'].values\n",
    "        if 'gender_1' in x_test.columns:\n",
    "            df_test_mix['gender_1'] = x_test['gender_1'].values\n",
    "        if 'ap_age_0' in x_test.columns:\n",
    "            df_test_mix['ap_age_0'] = x_test['ap_age_0'].values\n",
    "        if 'ap_age_1' in x_test.columns:\n",
    "            df_test_mix['ap_age_1'] = x_test['ap_age_1'].values\n",
    "        if 'ap_age_2' in x_test.columns:\n",
    "            df_test_mix['ap_age_2'] = x_test['ap_age_2'].values\n",
    "\n",
    "        if 'gender' in x_test.columns:\n",
    "            df_test_mix['gender'] = x_test['gender'].values\n",
    "        if 'ap_age' in x_test.columns:\n",
    "            df_test_mix['ap_age'] = x_test['ap_age'].values\n",
    "            \n",
    "        if 'gender_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['gender_dummy_most_frequent'] = x_test['gender_dummy_most_frequent'].values\n",
    "        if 'ap_age_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['ap_age_dummy_most_frequent'] = x_test['ap_age_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['gender_dummy_stratified'] = x_test['gender_dummy_stratified'].values\n",
    "        if 'ap_age_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['ap_age_dummy_stratified'] = x_test['ap_age_dummy_stratified'].values\n",
    "\n",
    "        if 'gender_predict' in x_test.columns:\n",
    "            df_test_mix['gender_predict'] = x_test['gender_predict'].values\n",
    "        if 'ap_age_predict' in x_test.columns:\n",
    "            df_test_mix['ap_age_predict'] = x_test['ap_age_predict'].values\n",
    "            \n",
    "        test_pred = clf_final.predict(df_test_mix)\n",
    "\n",
    "        f1, precision, recall, accuracy = eval_measures(y_test, test_pred)\n",
    "        print(\"Executado para : \" + str(author) + ' autores - ' + str(now.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "\n",
    "        return pd.DataFrame(data=[[author, f1, precision, recall, accuracy, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])\n",
    "    except Exception as e:\n",
    "        #print('erro na simulacao')\n",
    "        print(traceback.print_exc())\n",
    "        return pd.DataFrame(data=[[0.0, 0.0, 0.0, 0.0, 0.0, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list_11 = []\n",
    "\n",
    "#individuais\n",
    "ca_list_02 = ['gender']\n",
    "ca_list_04 = ['ap_age']\n",
    "\n",
    "ca_list_12 = ['gender_predict']\n",
    "ca_list_14 = ['ap_age_predict']\n",
    "\n",
    "ca_list_221 = ['gender_dummy_stratified']\n",
    "ca_list_241 = ['ap_age_dummy_stratified']\n",
    "\n",
    "ca_list_222 = ['gender_dummy_most_frequent']\n",
    "ca_list_242 = ['ap_age_dummy_most_frequent']\n",
    "\n",
    "ca_list_32 = ['gender_0', 'gender_1']\n",
    "ca_list_34 = ['ap_age_0', 'ap_age_1', 'ap_age_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "#rand.shuffle(list_authors_aa_selection)\n",
    "#author_list_filter = list_authors_aa_selection[:2]\n",
    "\n",
    "#run_simulation(df_filter, 1, 1, ca_list_36, author_list_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing simulation number: 0 data: 03/05/2020 18:17:14\n",
      "Executado para : 2 autores - 03/05/2020 18:17:14\n",
      "Executado para : 2 autores - 03/05/2020 18:17:14\n",
      "Executado para : 2 autores - 03/05/2020 18:17:14\n",
      "Executado para : 2 autores - 03/05/2020 18:17:14\n",
      "Executado para : 2 autores - 03/05/2020 18:17:14\n",
      "Executado para : 4 autores - 03/05/2020 18:17:14\n",
      "Executado para : 4 autores - 03/05/2020 18:17:14\n",
      "Executado para : 4 autores - 03/05/2020 18:17:14\n",
      "Executado para : 4 autores - 03/05/2020 18:17:14\n",
      "Executado para : 4 autores - 03/05/2020 18:17:14\n",
      "Executado para : 6 autores - 03/05/2020 18:17:14\n",
      "Executado para : 6 autores - 03/05/2020 18:17:14\n",
      "Executado para : 6 autores - 03/05/2020 18:17:14\n",
      "Executado para : 6 autores - 03/05/2020 18:17:14\n",
      "Executado para : 6 autores - 03/05/2020 18:17:14\n",
      "Executado para : 8 autores - 03/05/2020 18:17:14\n",
      "Executado para : 8 autores - 03/05/2020 18:17:14\n",
      "Executado para : 8 autores - 03/05/2020 18:17:14\n",
      "Executado para : 8 autores - 03/05/2020 18:17:14\n",
      "Executado para : 8 autores - 03/05/2020 18:17:14\n",
      "Executado para : 10 autores - 03/05/2020 18:17:14\n",
      "Executado para : 10 autores - 03/05/2020 18:17:14\n",
      "Executado para : 10 autores - 03/05/2020 18:17:14\n",
      "Executado para : 10 autores - 03/05/2020 18:17:14\n",
      "Executado para : 10 autores - 03/05/2020 18:17:14\n",
      "Executado para : 12 autores - 03/05/2020 18:17:14\n",
      "Executado para : 12 autores - 03/05/2020 18:17:14\n",
      "Executado para : 12 autores - 03/05/2020 18:17:14\n",
      "Executado para : 12 autores - 03/05/2020 18:17:14\n",
      "Executado para : 12 autores - 03/05/2020 18:17:14\n",
      "Executado para : 14 autores - 03/05/2020 18:17:14\n",
      "Executado para : 14 autores - 03/05/2020 18:17:14\n",
      "Executado para : 14 autores - 03/05/2020 18:17:14\n",
      "Executado para : 14 autores - 03/05/2020 18:17:14\n",
      "Executado para : 14 autores - 03/05/2020 18:17:14\n",
      "Executado para : 16 autores - 03/05/2020 18:17:14\n",
      "Executado para : 16 autores - 03/05/2020 18:17:14\n",
      "Executado para : 16 autores - 03/05/2020 18:17:14\n",
      "Executado para : 16 autores - 03/05/2020 18:17:14\n",
      "Executado para : 16 autores - 03/05/2020 18:17:14\n",
      "Executado para : 18 autores - 03/05/2020 18:17:14\n",
      "Executado para : 18 autores - 03/05/2020 18:17:14\n",
      "Executado para : 18 autores - 03/05/2020 18:17:14\n",
      "Executado para : 18 autores - 03/05/2020 18:17:14\n",
      "Executado para : 18 autores - 03/05/2020 18:17:14\n",
      "Executado para : 20 autores - 03/05/2020 18:17:14\n",
      "Executado para : 20 autores - 03/05/2020 18:17:14\n",
      "Executado para : 20 autores - 03/05/2020 18:17:14\n",
      "Executado para : 20 autores - 03/05/2020 18:17:14\n",
      "Executado para : 20 autores - 03/05/2020 18:17:14\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'output/kbest_proprio_es_03_05_2020__18_17_14.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-4c3f7504a024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m#df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_242, author_list_filter)) # baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m#df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_34, author_list_filter)) # baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'output'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'kbest_proprio_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlanguage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%d_%m_%Y__%H_%M_%S\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".xlsx\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m#df_metrics = df_metrics.append(run_simulation(df_train, j, i, ca_list))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mto_excel\u001b[0;34m(self, excel_writer, sheet_name, na_rep, float_format, columns, header, index, index_label, startrow, startcol, engine, merge_cells, encoding, inf_rep, verbose, freeze_panes)\u001b[0m\n\u001b[1;32m   1764\u001b[0m         formatter.write(excel_writer, sheet_name=sheet_name, startrow=startrow,\n\u001b[1;32m   1765\u001b[0m                         \u001b[0mstartcol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstartcol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_panes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfreeze_panes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1766\u001b[0;31m                         engine=engine)\n\u001b[0m\u001b[1;32m   1767\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1768\u001b[0m     def to_stata(self, fname, convert_dates=None, write_index=True,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/formats/excel.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, writer, sheet_name, startrow, startcol, freeze_panes, engine)\u001b[0m\n\u001b[1;32m    652\u001b[0m                            freeze_panes=freeze_panes)\n\u001b[1;32m    653\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mneed_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m             \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/pandas/io/excel.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1730\u001b[0m         \"\"\"\n\u001b[1;32m   1731\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m     def write_cells(self, cells, sheet_name=None, startrow=0, startcol=0,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    309\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileclosed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileclosed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    638\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    639\u001b[0m         xlsx_file = ZipFile(self.filename, \"w\", compression=ZIP_DEFLATED,\n\u001b[0;32m--> 640\u001b[0;31m                             allowZip64=self.allow_zip64)\n\u001b[0m\u001b[1;32m    641\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m         \u001b[0;31m# Add XML sub-files to the Zip file with their Excel filename.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'output/kbest_proprio_es_03_05_2020__18_17_14.xlsx'"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 20):\n",
    "    rand.shuffle(list_authors_aa_selection)\n",
    "\n",
    "    now = datetime.now()\n",
    "\n",
    "    print(\"Executing simulation number: \" + str(i) + \" data: \" + str(now.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "\n",
    "    for j in range(2, limit_authors_aa_selection + 2, 2):\n",
    "        \n",
    "        author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "        df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "        \n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_11, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_02, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_12, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_221, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_222, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_32, author_list_filter)) # baseline\n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_04, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_14, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_241, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_242, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_34, author_list_filter)) # baseline\n",
    "    df_metrics.to_excel(os.path.join('output', 'kbest_proprio_' + language + \"_\" + str(now.strftime(\"%d_%m_%Y__%H_%M_%S\")) + \".xlsx\"))\n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_train, j, i, ca_list))\n",
    "        #print(str(authors_shuffle[:j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste McNemar's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mcnemar(j, ca_classf_list_1, ca_classf_list_2):\n",
    "\n",
    "    clf_final_classif_1 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "    clf_final_classif_2 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "    author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "    df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_1], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_1.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred = clf_final_classif_1.predict(df_test_mix)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_2], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_2.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred2 = clf_final_classif_2.predict(df_test_mix)\n",
    "\n",
    "    df_mcnemar_test = pd.DataFrame()\n",
    "    df_mcnemar_test['model_pred_classif_1'] = test_pred\n",
    "    df_mcnemar_test['model_pred_classif_2'] = test_pred2\n",
    "    df_mcnemar_test['original_label'] = y_test.values\n",
    "\n",
    "    df_mcnemar_test['classf_1'] = np.where(df_mcnemar_test['model_pred_classif_1']==df_mcnemar_test['original_label'], 0, 1)\n",
    "    df_mcnemar_test['classf_2'] = np.where(df_mcnemar_test['model_pred_classif_2']==df_mcnemar_test['original_label'], 0, 1)\n",
    "\n",
    "    print(\"classf_1 acc: \" + str(1-sum(df_mcnemar_test['classf_1'])/len(df_mcnemar_test)))\n",
    "    print(\"classf_2 acc: \" + str(1-sum(df_mcnemar_test['classf_2'])/len(df_mcnemar_test)))\n",
    "\n",
    "    data_crosstab = pd.crosstab(df_mcnemar_test['classf_1'],  \n",
    "                                df_mcnemar_test['classf_2'], \n",
    "                                margins = False) \n",
    "    print(data_crosstab)\n",
    "\n",
    "    \n",
    "    count_contingence_table = np.where(data_crosstab>25, 1, 0).sum()\n",
    "    \n",
    "    if count_contingence_table==4:\n",
    "        result = mcnemar(data_crosstab, exact=False, correction=True)\n",
    "        print(\"Todos os termos maiores que 25\")\n",
    "    else:\n",
    "        print(\"Algum termo menor que 25\")\n",
    "        result = mcnemar(data_crosstab, exact=True)\n",
    "\n",
    "    print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "    # interpret the p-value\n",
    "    alpha = 0.05\n",
    "    if result.pvalue > alpha:\n",
    "        print('Same proportions of errors (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Espanhol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5756411925530529\n",
      "classf_2 acc: 0.6724384845723212\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8809    34\n",
      "1         1521  4998\n",
      "Todos os termos maiores que 25\n",
      "statistic=1420.062, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5756411925530529\n",
      "classf_2 acc: 0.7474287202187215\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8837     6\n",
      "1         2645  3874\n",
      "Algum termo menor que 25\n",
      "statistic=6.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.6724384845723212\n",
      "classf_2 acc: 0.7474287202187215\n",
      "classf_2      0     1\n",
      "classf_1             \n",
      "0         10074   256\n",
      "1          1408  3624\n",
      "Todos os termos maiores que 25\n",
      "statistic=796.154, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_12, ca_list_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Francês"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5820118484830351\n",
      "classf_2 acc: 0.6435282149482378\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         9705    21\n",
      "1         1049  5936\n",
      "Algum termo menor que 25\n",
      "statistic=21.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5820118484830351\n",
      "classf_2 acc: 0.7244330081981928\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         9715    11\n",
      "1         2391  4594\n",
      "Algum termo menor que 25\n",
      "statistic=11.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.6435282149482378\n",
      "classf_2 acc: 0.7244330081981928\n",
      "classf_2      0     1\n",
      "classf_1             \n",
      "0         10467   287\n",
      "1          1639  4318\n",
      "Todos os termos maiores que 25\n",
      "statistic=947.664, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_12, ca_list_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Português"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5672690763052208\n",
      "classf_2 acc: 0.6373185047883843\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         7328    17\n",
      "1          924  4679\n",
      "Algum termo menor que 25\n",
      "statistic=17.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5672690763052208\n",
      "classf_2 acc: 0.6713005869632376\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         7338     7\n",
      "1         1354  4249\n",
      "Algum termo menor que 25\n",
      "statistic=7.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.6373185047883843\n",
      "classf_2 acc: 0.6713005869632376\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         7919   333\n",
      "1          773  3923\n",
      "Todos os termos maiores que 25\n",
      "statistic=174.250, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_12, ca_list_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Italiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.4990723562152134\n",
      "classf_2 acc: 0.5252690166975882\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         6710    15\n",
      "1          368  6382\n",
      "Algum termo menor que 25\n",
      "statistic=15.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.4990723562152134\n",
      "classf_2 acc: 0.5539146567717996\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         6720     5\n",
      "1          744  6006\n",
      "Algum termo menor que 25\n",
      "statistic=5.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5252690166975882\n",
      "classf_2 acc: 0.5539146567717996\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         6993    85\n",
      "1          471  5926\n",
      "Todos os termos maiores que 25\n",
      "statistic=266.592, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_12, ca_list_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alemão"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5395596419066053\n",
      "classf_2 acc: 0.6304742317928865\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8886    34\n",
      "1         1537  6075\n",
      "Todos os termos maiores que 25\n",
      "statistic=1436.031, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5395596419066053\n",
      "classf_2 acc: 0.6846721509799177\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8906    14\n",
      "1         2413  5199\n",
      "Algum termo menor que 25\n",
      "statistic=14.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.6304742317928865\n",
      "classf_2 acc: 0.6846721509799177\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         9991   432\n",
      "1         1328  4781\n",
      "Todos os termos maiores que 25\n",
      "statistic=455.128, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_12, ca_list_32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Holândes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5322091950994599\n",
      "classf_2 acc: 0.5893162956132262\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8067    13\n",
      "1          880  6222\n",
      "Algum termo menor que 25\n",
      "statistic=13.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5322091950994599\n",
      "classf_2 acc: 0.5937952838888156\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8074     6\n",
      "1          941  6161\n",
      "Algum termo menor que 25\n",
      "statistic=6.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5893162956132262\n",
      "classf_2 acc: 0.5937952838888156\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         8382   565\n",
      "1          633  5602\n",
      "Todos os termos maiores que 25\n",
      "statistic=3.747, p-value=0.053\n",
      "Same proportions of errors (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_12, ca_list_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
