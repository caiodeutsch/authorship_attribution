{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import random as rand\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import normalize, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.datasets import load_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux-4.4.0-1112-aws-x86_64-with-debian-stretch-sid\n",
      "NumPy 1.14.3\n",
      "SciPy 1.1.0\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import scipy\n",
    "import sklearn\n",
    "print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n",
    "print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class ObfuscationTransformer(BaseEstimator):\n",
    "    def __init__(self,re_from=r'(\\b)(\\w{0,2})\\w+(\\w{1,3})(\\b)', re_to=r'\\1\\2XX\\3\\4', return_copy=True):\n",
    "        self.re_from = re_from\n",
    "        self.re_to = re_to\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.array(X).copy();\n",
    "        for i in range(len(X)):\n",
    "            X[i] = re.sub(self.re_from,self.re_to, X[i])\n",
    "        \n",
    "        return X;\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gt,\n",
    "                  pred)\n",
    "\n",
    "    return f1,precision,recall,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineCharacter = Pipeline([\n",
    "    ('vect',   TfidfVectorizer(\n",
    "            analyzer='char',\n",
    "            min_df=0.05,\n",
    "            max_df=1.0,\n",
    "            ngram_range=(2,5),\n",
    "            lowercase=False,\n",
    "            norm='l2',\n",
    "            sublinear_tf=True)),\n",
    "    ('dense',  DenseTransformer()),\n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    ('transf', PCA(0.999)),\n",
    "    ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "])\n",
    "\n",
    "pipelineObfuscator = Pipeline([\n",
    "        ('obs',ObfuscationTransformer(re_from=r'\\w',re_to='x')),\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='char',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(2,5),\n",
    "                lowercase=False,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "\n",
    "pipelineWord = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='word',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(1,3),\n",
    "                lowercase=True,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')),\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/lab/Experimentos/experimento_3_corpus_b5_post')\n",
    "input_summary_file = os.path.join('input', 'subjects_trim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "### le tabel summary\n",
    "df_summary = pd.read_csv(input_summary_file, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "### le textos\n",
    "textsDir = os.path.join('input', 'pt-gender')\n",
    "texts = load_files(textsDir, \n",
    "    description=None, categories=['male', 'female'], \n",
    "    load_content=True, encoding='utf-8', shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = []\n",
    "\n",
    "for i in range(0, len(texts.filenames)):\n",
    "    id_list.append(texts.filenames[i].split('-')[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data=texts.data, columns=['text'])\n",
    "df['id_author'] = id_list\n",
    "df['id_author'] = df['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_summary, how='left', left_on='id_author', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['age']>0]\n",
    "df = df[df['ti'].notnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_author</th>\n",
       "      <th>id</th>\n",
       "      <th>words</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>733.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>733.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>659.148704</td>\n",
       "      <td>659.148704</td>\n",
       "      <td>845.085948</td>\n",
       "      <td>24.607094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>339.125259</td>\n",
       "      <td>339.125259</td>\n",
       "      <td>577.299772</td>\n",
       "      <td>6.482937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>399.000000</td>\n",
       "      <td>399.000000</td>\n",
       "      <td>439.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>692.000000</td>\n",
       "      <td>692.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>952.000000</td>\n",
       "      <td>952.000000</td>\n",
       "      <td>1137.000000</td>\n",
       "      <td>26.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2226.000000</td>\n",
       "      <td>2226.000000</td>\n",
       "      <td>4663.000000</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id_author           id        words         age\n",
       "count   733.000000   733.000000   733.000000  733.000000\n",
       "mean    659.148704   659.148704   845.085948   24.607094\n",
       "std     339.125259   339.125259   577.299772    6.482937\n",
       "min      17.000000    17.000000    10.000000   18.000000\n",
       "25%     399.000000   399.000000   439.000000   21.000000\n",
       "50%     692.000000   692.000000   742.000000   23.000000\n",
       "75%     952.000000   952.000000  1137.000000   26.000000\n",
       "max    2226.000000  2226.000000  4663.000000   61.000000"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['gender_final'] = np.where(df['gender']=='male', 1, 0)\n",
    "df['age_final'] = np.where(df['age']<=20, \n",
    "                           0, \n",
    "                           np.where(df['age']>=28, \n",
    "                                    2, 1))\n",
    "df['it_final'] = np.where(df['ti']=='yes', 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df['words']\n",
    "del df['id']\n",
    "del df['age']\n",
    "del df['ti']\n",
    "del df['gender']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    text_list = df['text'].iloc[i].split('.')\n",
    "    author_list = [df['id_author'].iloc[i]]*len(text_list)\n",
    "    df_inter = pd.DataFrame(data=[text_list, author_list]).T\n",
    "    df_inter = df_inter.rename(columns={0: 'text', 1: 'id_author'})\n",
    "    \n",
    "    df_final = df_final.append(df_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_statistics = df_final.copy()\n",
    "df_final_statistics['number_of_words'] = df_final['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de unidades: 128310\n",
      "Total de palavras: 1951259\n",
      "Total de palavras/unidade: 15.207380562699711\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de unidades: \" + str(len(df_final_statistics)))\n",
    "print(\"Total de palavras: \" + str(sum(df_final_statistics['number_of_words'])))\n",
    "print(\"Total de palavras/unidade: \" + str(sum(df_final_statistics['number_of_words'])/len(df_final_statistics)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selecao de autores com mais textos\n",
    "limit_authors_aa_selection = 20\n",
    "list_authors_aa_selection = list(df_final['id_author'].value_counts()[:limit_authors_aa_selection].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisao de bases\n",
    "df_aa = df[df['id_author'].isin(list_authors_aa_selection)]\n",
    "df_ca = df[~df['id_author'].isin(list_authors_aa_selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kbest = Pipeline([\n",
    "    ('vect', TfidfVectorizer()), \n",
    "    ('k_best', SelectKBest(f_classif)),\n",
    "    ('clf', LogisticRegression(random_state=42, n_jobs=6))\n",
    "])\n",
    "    \n",
    "parameters_kbest = {    \n",
    "    'k_best__k': (range(3000,20000,1000))\n",
    "}\n",
    "\n",
    "grid_search_resp = GridSearchCV(pipeline_kbest,\n",
    "                               parameters_kbest,\n",
    "                               cv=10,\n",
    "                               scoring='f1_macro',\n",
    "                               n_jobs=6,\n",
    "                               #verbose=10\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list = ['gender_final', 'it_final', 'age_final']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#k_best_dict = {}\n",
    "\n",
    "#for ca in ca_list:  \n",
    "#    warnings.filterwarnings(\"ignore\")\n",
    "#    grid_search_resp.fit(df_ca['text'], df_ca[ca])\n",
    "#    print('Finalizado, tarefa: ' + str(ca))\n",
    "\n",
    "#    k_best_dict.update({ca: grid_search_resp.best_estimator_.get_params()['k_best__k']})\n",
    "#print(k_best_dict)\n",
    "\n",
    "k_best_dict = {'gender_final': 13000, \n",
    "               'it_final': 6000, \n",
    "               'age_final': 16000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "### Utilizando o kbest encontrado\n",
    "#k_best_dict = {'gender_final': 1800,\n",
    "#               'it_final': 7800,\n",
    "#               'age_final': 9800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorized_train = vect.fit_transform(df_ca['text'])\n",
    "text_vectorized_test = vect.transform(df_aa['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_test_ca = pd.DataFrame()\n",
    "#df_test_ca['id_author'] = df_aa['id_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca;accuracy;precision_macro;recall_macro;f1_macro\n",
      "         ca_var        f1  precision    recall  accuracy\n",
      "0  gender_final  0.607843   0.607843  0.607843       0.8\n",
      "     ca_var        f1  precision    recall  accuracy\n",
      "0  it_final  0.722222   0.722222  0.722222       0.9\n",
      "      ca_var        f1  precision    recall  accuracy\n",
      "0  age_final  0.423687   0.563492  0.449206      0.45\n"
     ]
    }
   ],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = list(df_aa['id_author'])\n",
    "\n",
    "print('ca;accuracy;precision_macro;recall_macro;f1_macro')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "\n",
    "    k_best = k_best_dict[ca_var]\n",
    "    sel = SelectKBest(k = k_best)\n",
    "    ft = sel.fit(text_vectorized_train, df_ca[ca_var])\n",
    "    train_best = ft.transform(text_vectorized_train)\n",
    "\n",
    "    clf.fit(train_best, df_ca[ca_var])\n",
    "\n",
    "    test_best = ft.transform(text_vectorized_test)\n",
    "\n",
    "    predicted = clf.predict(test_best) #com variavel categorica\n",
    "    predicted_prob = clf.predict_proba(test_best) #com probabilidade de variavel\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_aa[ca_var], predicted)\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))\n",
    "\n",
    "    df_test_ca[ca_var + '_predict'] = predicted\n",
    "    \n",
    "    # probs\n",
    "    df_temp = pd.DataFrame(predicted_prob)\n",
    "    df_temp = df_temp.add_prefix(ca_var + '_')\n",
    "    df_test_ca = df_test_ca.join(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='stratified') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_stratified'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='most_frequent') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_most_frequent'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca.copy() \n",
    "#df_aa[['gender_final', 'age_final', 'it_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca_baseline.merge(df_aa[['id_author','gender_final', 'age_final', 'it_final']],\n",
    "                          left_on='id_author', right_on='id_author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca;accuracy;precision_macro;recall_macro;f1_macro\n",
      "         ca_var        f1  precision  recall  accuracy\n",
      "0  gender_final  0.459459      0.425     0.5      0.85\n",
      "     ca_var        f1  precision  recall  accuracy\n",
      "0  it_final  0.473684       0.45     0.5       0.9\n",
      "      ca_var       f1  precision    recall  accuracy\n",
      "0  age_final  0.17284   0.116667  0.333333      0.35\n"
     ]
    }
   ],
   "source": [
    "#baseline CA\n",
    "print('ca;accuracy;precision_macro;recall_macro;f1_macro')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_test_ca_baseline[ca_var], df_test_ca_baseline[ca_var + '_dummy_most_frequent'])\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_final_aa = df_final[df_final['id_author'].isin(list_authors_aa_selection)]\n",
    "df_final_aa['id_author'] = df_final_aa['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_aa = df_final_aa.merge(df_test_ca, how='left', left_on='id_author', right_on='id_author')\n",
    "df_final_aa = df_final_aa.merge(df[['id_author', 'gender_final','it_final','age_final']], how='left', left_on='id_author', right_on='id_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_aa = df_final_aa[df_final_aa['text'].apply(len)>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "scoring = ['accuracy','precision_macro', 'recall_macro', 'f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender_final</th>\n",
       "      <th>it_final</th>\n",
       "      <th>age_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>1119</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1354</th>\n",
       "      <td>430</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>913</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>1147</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3272</th>\n",
       "      <td>946</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4062</th>\n",
       "      <td>1166</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4651</th>\n",
       "      <td>1165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5352</th>\n",
       "      <td>919</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6039</th>\n",
       "      <td>584</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6954</th>\n",
       "      <td>1016</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7857</th>\n",
       "      <td>479</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>846</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9297</th>\n",
       "      <td>821</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10752</th>\n",
       "      <td>1124</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11623</th>\n",
       "      <td>324</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12309</th>\n",
       "      <td>148</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12945</th>\n",
       "      <td>688</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13644</th>\n",
       "      <td>826</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14348</th>\n",
       "      <td>125</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_author  gender_final  it_final  age_final\n",
       "0           1163             0         0          1\n",
       "616         1119             0         0          1\n",
       "1354         430             0         0          1\n",
       "1985         913             0         0          2\n",
       "2587        1147             0         1          0\n",
       "3272         946             0         0          0\n",
       "4062        1166             0         0          2\n",
       "4651        1165             0         0          1\n",
       "5352         919             0         0          0\n",
       "6039         584             0         0          2\n",
       "6954        1016             0         0          2\n",
       "7857         479             0         0          2\n",
       "8583         846             1         0          2\n",
       "9297         821             1         1          2\n",
       "10752       1124             0         0          1\n",
       "11623        324             0         0          1\n",
       "12309        148             0         0          2\n",
       "12945        688             1         0          1\n",
       "13644        826             0         0          2\n",
       "14348        125             0         0          2"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.drop_duplicates(subset=['id_author'])[['id_author', 'gender_final', 'it_final', 'age_final']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_final_aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(df_train, author, simulation, ca_list, author_list):\n",
    "    ### train\n",
    "    try:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_train[['text'] + ca_list], \n",
    "                                                        df_train['id_author'], \n",
    "                                                    test_size=0.3,random_state=rand.randint(0,900))\n",
    "\n",
    "        pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "        for p in pipelines:\n",
    "            p.fit(x_train['text'], y_train)\n",
    "\n",
    "        predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "        df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "        if 'gender_final_0' in x_train.columns:\n",
    "            df_train_mix['gender_final_0'] = x_train['gender_final_0'].values\n",
    "        if 'gender_final_1' in x_train.columns:\n",
    "            df_train_mix['gender_final_1'] = x_train['gender_final_1'].values\n",
    "        if 'it_final_0' in x_train.columns:\n",
    "            df_train_mix['it_final_0'] = x_train['it_final_0'].values\n",
    "        if 'it_final_1' in x_train.columns:\n",
    "            df_train_mix['it_final_1'] = x_train['it_final_1'].values\n",
    "        if 'age_final_0' in x_train.columns:\n",
    "            df_train_mix['age_final_0'] = x_train['age_final_0'].values\n",
    "        if 'age_final_1' in x_train.columns:\n",
    "            df_train_mix['age_final_1'] = x_train['age_final_1'].values\n",
    "        if 'age_final_2' in x_train.columns:\n",
    "            df_train_mix['age_final_2'] = x_train['age_final_2'].values\n",
    "\n",
    "        if 'gender_final_predict' in x_train.columns:\n",
    "            df_train_mix['gender_final_predict'] = x_train['gender_final_predict'].values\n",
    "        if 'it_final_predict' in x_train.columns:\n",
    "            df_train_mix['it_final_predict'] = x_train['it_final_predict'].values\n",
    "        if 'age_final_predict' in x_train.columns:\n",
    "            df_train_mix['age_final_predict'] = x_train['age_final_predict'].values\n",
    "            \n",
    "        if 'gender_final_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['gender_final_dummy_stratified'] = x_train['gender_final_dummy_stratified'].values\n",
    "        if 'it_final_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['it_final_dummy_stratified'] = x_train['it_final_dummy_stratified'].values\n",
    "        if 'age_final_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['age_final_dummy_stratified'] = x_train['age_final_dummy_stratified'].values\n",
    "\n",
    "        if 'gender_final_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['gender_final_dummy_most_frequent'] = x_train['gender_final_dummy_most_frequent'].values\n",
    "        if 'it_final_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['it_final_dummy_most_frequent'] = x_train['it_final_dummy_most_frequent'].values\n",
    "        if 'age_final_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['age_final_dummy_most_frequent'] = x_train['age_final_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_final' in x_train.columns:\n",
    "            df_train_mix['gender_final'] = x_train['gender_final'].values\n",
    "        if 'it_final' in x_train.columns:\n",
    "            df_train_mix['it_final'] = x_train['it_final'].values\n",
    "        if 'age_final' in x_train.columns:\n",
    "            df_train_mix['age_final'] = x_train['age_final'].values\n",
    "\n",
    "        clf_final.fit(df_train_mix, y_train)\n",
    "\n",
    "        #test\n",
    "        predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "        df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "        if 'gender_final_0' in x_test.columns:\n",
    "            df_test_mix['gender_final_0'] = x_test['gender_final_0'].values\n",
    "        if 'gender_final_1' in x_test.columns:\n",
    "            df_test_mix['gender_final_1'] = x_test['gender_final_1'].values\n",
    "        if 'it_final_0' in x_test.columns:\n",
    "            df_test_mix['it_final_0'] = x_test['it_final_0'].values\n",
    "        if 'it_final_1' in x_test.columns:\n",
    "            df_test_mix['it_final_1'] = x_test['it_final_1'].values\n",
    "        if 'age_final_0' in x_test.columns:\n",
    "            df_test_mix['age_final_0'] = x_test['age_final_0'].values\n",
    "        if 'age_final_1' in x_test.columns:\n",
    "            df_test_mix['age_final_1'] = x_test['age_final_1'].values\n",
    "        if 'age_final_2' in x_test.columns:\n",
    "            df_test_mix['age_final_2'] = x_test['age_final_2'].values\n",
    "\n",
    "        if 'gender_final_predict' in x_test.columns:\n",
    "            df_test_mix['gender_final_predict'] = x_test['gender_final_predict'].values\n",
    "        if 'it_final_predict' in x_test.columns:\n",
    "            df_test_mix['it_final_predict'] = x_test['it_final_predict'].values\n",
    "        if 'age_final_predict' in x_test.columns:\n",
    "            df_test_mix['age_final_predict'] = x_test['age_final_predict'].values\n",
    "            \n",
    "        if 'gender_final_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['gender_final_dummy_stratified'] = x_test['gender_final_dummy_stratified'].values\n",
    "        if 'it_final_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['it_final_dummy_stratified'] = x_test['it_final_dummy_stratified'].values\n",
    "        if 'age_final_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['age_final_dummy_stratified'] = x_test['age_final_dummy_stratified'].values\n",
    "\n",
    "        if 'gender_final_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['gender_final_dummy_most_frequent'] = x_test['gender_final_dummy_most_frequent'].values\n",
    "        if 'it_final_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['it_final_dummy_most_frequent'] = x_test['it_final_dummy_most_frequent'].values\n",
    "        if 'age_final_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['age_final_dummy_most_frequent'] = x_test['age_final_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_final' in x_test.columns:\n",
    "            df_test_mix['gender_final'] = x_test['gender_final'].values\n",
    "        if 'it_final' in x_test.columns:\n",
    "            df_test_mix['it_final'] = x_test['it_final'].values\n",
    "        if 'age_final' in x_test.columns:\n",
    "            df_test_mix['age_final'] = x_test['age_final'].values\n",
    "            \n",
    "        test_pred = clf_final.predict(df_test_mix)\n",
    "\n",
    "        f1, precision, recall, accuracy = eval_measures(y_test, test_pred)\n",
    "\n",
    "        return pd.DataFrame(data=[[author, f1, precision, recall, accuracy, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])\n",
    "    except Exception as e:\n",
    "        #print('erro na simulacao')\n",
    "        print(traceback.print_exc())\n",
    "        return pd.DataFrame(data=[[0.0, 0.0, 0.0, 0.0, 0.0, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list_11 = []\n",
    "\n",
    "#individuais\n",
    "ca_list_02 = ['gender_final']\n",
    "ca_list_03 = ['it_final']\n",
    "ca_list_04 = ['age_final']\n",
    "\n",
    "ca_list_12 = ['gender_final_predict']\n",
    "ca_list_13 = ['it_final_predict']\n",
    "ca_list_14 = ['age_final_predict']\n",
    "\n",
    "ca_list_112 = ['gender_final_predict', 'it_final_predict']\n",
    "ca_list_113 = ['it_final_predict', 'age_final_predict']\n",
    "ca_list_114 = ['gender_final_predict', 'age_final_predict']\n",
    "ca_list_115 = ['gender_final_predict', 'it_final_predict', 'age_final_predict']\n",
    "\n",
    "ca_list_221 = ['gender_final_dummy_stratified']\n",
    "ca_list_231 = ['it_final_dummy_stratified']\n",
    "ca_list_241 = ['age_final_dummy_stratified']\n",
    "\n",
    "ca_list_222 = ['gender_final_dummy_most_frequent']\n",
    "ca_list_232 = ['it_final_dummy_most_frequent']\n",
    "ca_list_242 = ['age_final_dummy_most_frequent']\n",
    "\n",
    "ca_list_1222 = ['gender_final_dummy_most_frequent', 'it_final_dummy_most_frequent']\n",
    "ca_list_1232 = ['it_final_dummy_most_frequent', 'age_final_dummy_most_frequent']\n",
    "ca_list_1242 = ['gender_final_dummy_most_frequent','age_final_dummy_most_frequent']\n",
    "ca_list_1252 = ['gender_final_dummy_most_frequent', 'it_final_dummy_most_frequent', 'age_final_dummy_most_frequent']\n",
    "\n",
    "ca_list_32 = ['gender_final_0', 'gender_final_1']\n",
    "ca_list_33 = ['it_final_0', 'it_final_1']\n",
    "ca_list_34 = ['age_final_0', 'age_final_1', 'age_final_2']\n",
    "\n",
    "ca_list_132 = ['gender_final_0', 'gender_final_1', 'it_final_0', 'it_final_1']\n",
    "ca_list_133 = ['it_final_0', 'it_final_1', 'age_final_0', 'age_final_1', 'age_final_2']\n",
    "ca_list_134 = ['gender_final_0', 'gender_final_1', 'age_final_0', 'age_final_1', 'age_final_2']\n",
    "ca_list_135 = ['gender_final_0', 'gender_final_1', 'it_final_0', 'it_final_1', 'age_final_0', 'age_final_1', 'age_final_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing simulation number: 0 data: 20/07/2020 15:42:22\n",
      "Executing simulation number: 1 data: 20/07/2020 15:43:19\n",
      "Executing simulation number: 2 data: 20/07/2020 15:44:22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-42-691b63822783>\", line 10, in run_simulation\n",
      "    p.fit(x_train['text'], y_train)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 248, in fit\n",
      "    Xt, fit_params = self._fit(X, y, **fit_params)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 213, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 362, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\", line 348, in fit_transform\n",
      "    U, S, V = self._fit(X)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\", line 392, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\", line 416, in _fit_full\n",
      "    U, S, V = linalg.svd(X, full_matrices=False)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/scipy/linalg/decomp_svd.py\", line 132, in svd\n",
      "    raise LinAlgError(\"SVD did not converge\")\n",
      "numpy.linalg.linalg.LinAlgError: SVD did not converge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"<ipython-input-42-691b63822783>\", line 10, in run_simulation\n",
      "    p.fit(x_train['text'], y_train)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 248, in fit\n",
      "    Xt, fit_params = self._fit(X, y, **fit_params)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 213, in _fit\n",
      "    **fit_params_steps[name])\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\", line 362, in __call__\n",
      "    return self.func(*args, **kwargs)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\", line 581, in _fit_transform_one\n",
      "    res = transformer.fit_transform(X, y, **fit_params)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\", line 348, in fit_transform\n",
      "    U, S, V = self._fit(X)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\", line 392, in _fit\n",
      "    return self._fit_full(X, n_components)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/pca.py\", line 416, in _fit_full\n",
      "    U, S, V = linalg.svd(X, full_matrices=False)\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/scipy/linalg/decomp_svd.py\", line 132, in svd\n",
      "    raise LinAlgError(\"SVD did not converge\")\n",
      "numpy.linalg.linalg.LinAlgError: SVD did not converge\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "Executing simulation number: 3 data: 20/07/2020 15:45:20\n",
      "Executing simulation number: 4 data: 20/07/2020 15:46:20\n",
      "Executing simulation number: 5 data: 20/07/2020 15:47:21\n",
      "Executing simulation number: 6 data: 20/07/2020 15:48:16\n",
      "Executing simulation number: 7 data: 20/07/2020 15:49:19\n",
      "Executing simulation number: 8 data: 20/07/2020 15:50:19\n",
      "Executing simulation number: 9 data: 20/07/2020 15:51:22\n",
      "Executing simulation number: 10 data: 20/07/2020 15:52:26\n",
      "Executing simulation number: 11 data: 20/07/2020 15:53:27\n",
      "Executing simulation number: 12 data: 20/07/2020 15:54:28\n",
      "Executing simulation number: 13 data: 20/07/2020 15:55:25\n",
      "Executing simulation number: 14 data: 20/07/2020 15:56:27\n",
      "Executing simulation number: 15 data: 20/07/2020 15:57:32\n",
      "Executing simulation number: 16 data: 20/07/2020 15:58:29\n",
      "Executing simulation number: 17 data: 20/07/2020 15:59:31\n",
      "Executing simulation number: 18 data: 20/07/2020 16:00:33\n",
      "Executing simulation number: 19 data: 20/07/2020 16:01:33\n"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 20):\n",
    "    rand.shuffle(list_authors_aa_selection)\n",
    "\n",
    "    now = datetime.now()\n",
    "\n",
    "    print(\"Executing simulation number: \" + str(i) + \" data: \" + str(now.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "\n",
    "    for j in range(2, limit_authors_aa_selection + 2, 2):\n",
    "        \n",
    "        author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "        df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "        \n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_11, author_list_filter)) \n",
    "        \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_02, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_03, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_04, author_list_filter))\n",
    "        \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_12, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_13, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_14, author_list_filter))\n",
    "        \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_221, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_231, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_241, author_list_filter)) \n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_222, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_232, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_242, author_list_filter)) \n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_32, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_33, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_34, author_list_filter)) \n",
    "        \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_112, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_113, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_114, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_115, author_list_filter)) \n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_132, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_133, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_134, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_135, author_list_filter)) \n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_1222, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_1232, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_1242, author_list_filter)) \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_1252, author_list_filter)) \n",
    "        \n",
    "    df_metrics.to_excel(os.path.join('output', 'kbest_proprio_baseline_apenas_EACH_USP_' + str(now.strftime(\"%d_%m_%Y__%H_%M_%S\")) + \".xlsx\"))\n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_train, j, i, ca_list))\n",
    "        #print(str(authors_shuffle[:j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste McNemar's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "j=20\n",
    "ca_classf_list_1 = ca_list_12\n",
    "ca_classf_list_2 = ca_list_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mcnemar(j, ca_classf_list_1, ca_classf_list_2):\n",
    "\n",
    "    clf_final_classif_1 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "    clf_final_classif_2 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "    author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "    df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_1], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_1.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred = clf_final_classif_1.predict(df_test_mix)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_2], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_2.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred2 = clf_final_classif_2.predict(df_test_mix)\n",
    "\n",
    "    df_mcnemar_test = pd.DataFrame()\n",
    "    df_mcnemar_test['model_pred_classif_1'] = test_pred\n",
    "    df_mcnemar_test['model_pred_classif_2'] = test_pred2\n",
    "    df_mcnemar_test['original_label'] = y_test.values\n",
    "\n",
    "    df_mcnemar_test['classf_1'] = np.where(df_mcnemar_test['model_pred_classif_1']==df_mcnemar_test['original_label'], 0, 1)\n",
    "    df_mcnemar_test['classf_2'] = np.where(df_mcnemar_test['model_pred_classif_2']==df_mcnemar_test['original_label'], 0, 1)\n",
    "\n",
    "    print(\"classf_1 acc: \" + str(1-sum(df_mcnemar_test['classf_1'])/len(df_mcnemar_test)))\n",
    "    print(\"classf_2 acc: \" + str(1-sum(df_mcnemar_test['classf_2'])/len(df_mcnemar_test)))\n",
    "\n",
    "    data_crosstab = pd.crosstab(df_mcnemar_test['classf_1'],  \n",
    "                                df_mcnemar_test['classf_2'], \n",
    "                                margins = False) \n",
    "    print(data_crosstab)\n",
    "\n",
    "    \n",
    "    count_contingence_table = np.where(data_crosstab>25, 1, 0).sum()\n",
    "    \n",
    "    if count_contingence_table==4:\n",
    "        result = mcnemar(data_crosstab, exact=False, correction=True)\n",
    "        print(\"Todos os termos maiores que 25\")\n",
    "    else:\n",
    "        print(\"Algum termo menor que 25\")\n",
    "        result = mcnemar(data_crosstab, exact=True)\n",
    "\n",
    "    print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "    # interpret the p-value\n",
    "    alpha = 0.05\n",
    "    if result.pvalue > alpha:\n",
    "        print('Same proportions of errors (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.3733333333333333\n",
      "classf_2 acc: 0.4995833333333334\n",
      "classf_2    0     1\n",
      "classf_1           \n",
      "0         894     2\n",
      "1         305  1199\n",
      "Algum termo menor que 25\n",
      "statistic=2.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.3733333333333333\n",
      "classf_2 acc: 0.48124999999999996\n",
      "classf_2    0     1\n",
      "classf_1           \n",
      "0         895     1\n",
      "1         260  1244\n",
      "Algum termo menor que 25\n",
      "statistic=1.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.4995833333333334\n",
      "classf_2 acc: 0.48124999999999996\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         1051   148\n",
      "1          104  1097\n",
      "Todos os termos maiores que 25\n",
      "statistic=7.337, p-value=0.007\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_14, ca_list_34)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Debug Teste McNemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final_classif_1 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "clf_final_classif_2 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "author_list_filter = list_authors_aa_selection[:j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_1], \n",
    "                                                df_filter['id_author'], \n",
    "                                            test_size=0.3,random_state=42)\n",
    "\n",
    "pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pipelines:\n",
    "    p.fit(x_train['text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ca in ca_classf_list_1:\n",
    "    df_train_mix[ca] = x_train[ca].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=42, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_final_classif_1.fit(df_train_mix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ca in ca_classf_list_1:\n",
    "    df_test_mix[ca] = x_test[ca].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = clf_final_classif_1.predict(df_test_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_2], \n",
    "                                                df_filter['id_author'], \n",
    "                                            test_size=0.3,random_state=42)\n",
    "\n",
    "pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in pipelines:\n",
    "    p.fit(x_train['text'], y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for ca in ca_classf_list_2:\n",
    "    df_train_mix[ca] = x_train[ca].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=1, penalty='l2', random_state=42, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_final_classif_2.fit(df_train_mix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ca in ca_classf_list_2:\n",
    "    df_test_mix[ca] = x_test[ca].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred2 = clf_final_classif_2.predict(df_test_mix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mcnemar_test = pd.DataFrame()\n",
    "df_mcnemar_test['model_pred_classif_1'] = test_pred\n",
    "df_mcnemar_test['model_pred_classif_2'] = test_pred2\n",
    "df_mcnemar_test['original_label'] = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mcnemar_test['classf_1'] = np.where(df_mcnemar_test['model_pred_classif_1']==df_mcnemar_test['original_label'], 0, 1)\n",
    "df_mcnemar_test['classf_2'] = np.where(df_mcnemar_test['model_pred_classif_2']==df_mcnemar_test['original_label'], 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.43999999999999995\n",
      "classf_2 acc: 0.4575\n"
     ]
    }
   ],
   "source": [
    "print(\"classf_1 acc: \" + str(1-sum(df_mcnemar_test['classf_1'])/len(df_mcnemar_test)))\n",
    "print(\"classf_2 acc: \" + str(1-sum(df_mcnemar_test['classf_2'])/len(df_mcnemar_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         1002    54\n",
      "1           96  1248\n"
     ]
    }
   ],
   "source": [
    "data_crosstab = pd.crosstab(df_mcnemar_test['classf_1'],  \n",
    "                            df_mcnemar_test['classf_2'], \n",
    "                            margins = False) \n",
    "print(data_crosstab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "result = mcnemar(data_crosstab, exact=True)\n",
    "result = mcnemar(data_crosstab, exact=False, correction=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "statistic=54.000, p-value=0.001\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "# interpret the p-value\n",
    "alpha = 0.05\n",
    "if result.pvalue > alpha:\n",
    "    print('Same proportions of errors (fail to reject H0)')\n",
    "else:\n",
    "    print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
