{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import warnings\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import random as rand\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import normalize, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux-4.4.0-1112-aws-x86_64-with-debian-stretch-sid\n",
      "NumPy 1.14.3\n",
      "SciPy 1.1.0\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import scipy\n",
    "import sklearn\n",
    "print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n",
    "print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class ObfuscationTransformer(BaseEstimator):\n",
    "    def __init__(self,re_from=r'(\\b)(\\w{0,2})\\w+(\\w{1,3})(\\b)', re_to=r'\\1\\2XX\\3\\4', return_copy=True):\n",
    "        self.re_from = re_from\n",
    "        self.re_to = re_to\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.array(X).copy();\n",
    "        for i in range(len(X)):\n",
    "            X[i] = re.sub(self.re_from,self.re_to, X[i])\n",
    "        \n",
    "        return X;\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gt,\n",
    "                  pred)\n",
    "\n",
    "    return f1,precision,recall,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineCharacter = Pipeline([\n",
    "    ('vect',   TfidfVectorizer(\n",
    "            analyzer='char',\n",
    "            min_df=0.05,\n",
    "            max_df=1.0,\n",
    "            ngram_range=(2,5),\n",
    "            lowercase=False,\n",
    "            norm='l2',\n",
    "            sublinear_tf=True)),\n",
    "    ('dense',  DenseTransformer()),\n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    ('transf', PCA(0.999)),\n",
    "    ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "])\n",
    "\n",
    "pipelineObfuscator = Pipeline([\n",
    "        ('obs',ObfuscationTransformer(re_from=r'\\w',re_to='x')),\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='char',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(2,5),\n",
    "                lowercase=False,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "\n",
    "pipelineWord = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='word',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(1,3),\n",
    "                lowercase=True,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')),\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/lab/Experimentos/experimento_3/Ajustes_emails_23_01_2020')\n",
    "input_file = os.path.join('input', 'BRmoral-510-sept2019_params_prof.xlsx')\n",
    "df = pd.read_excel(input_file, sheet_name='read_pandas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'it': 'itf'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(df)):\n",
    "    text_list = df['text'].iloc[i].split('.')\n",
    "    author_list = [df['id_author'].iloc[i]]*len(text_list)\n",
    "    df_inter = pd.DataFrame(data=[text_list, author_list]).T\n",
    "    df_inter = df_inter.rename(columns={0: 'text', 1: 'id_author'})\n",
    "    \n",
    "    df_final = df_final.append(df_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_statistics = df_final.copy()\n",
    "df_final_statistics['number_of_words'] = df_final['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de unidades: 10236\n",
      "Total de palavras: 218218\n",
      "Total de palavras/unidade: 21.318679171551388\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de unidades: \" + str(len(df_final_statistics)))\n",
    "print(\"Total de palavras: \" + str(sum(df_final_statistics['number_of_words'])))\n",
    "print(\"Total de palavras/unidade: \" + str(sum(df_final_statistics['number_of_words'])/len(df_final_statistics)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selecao de autores com mais textos\n",
    "limit_authors_aa_selection = 20\n",
    "list_authors_aa_selection = list(df_final['id_author'].value_counts()[:limit_authors_aa_selection].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisao de bases\n",
    "df_aa = df[df['id_author'].isin(list_authors_aa_selection)]\n",
    "df_ca = df[~df['id_author'].isin(list_authors_aa_selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kbest = Pipeline([\n",
    "    ('vect', TfidfVectorizer()), \n",
    "    ('k_best', SelectKBest(f_classif)),\n",
    "    ('clf', LogisticRegression(random_state=42, n_jobs=6))\n",
    "])\n",
    "    \n",
    "parameters_kbest = {    \n",
    "    'k_best__k': (range(3000,11000,1000))\n",
    "}\n",
    "\n",
    "grid_search_resp = GridSearchCV(pipeline_kbest,\n",
    "                                parameters_kbest,\n",
    "                                cv=10,\n",
    "                                scoring='f1_macro',\n",
    "                                n_jobs=4,\n",
    "                                verbose=10\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list = ['gender', 'itf', 'ap_age', 'ap_school', 'ap_religion', 'ap_politics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_best_dict = {}\n",
    "\n",
    "#for ca in ca_list:\n",
    "   \n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "#    grid_search_resp.fit(df_ca['text'], df_ca[ca])\n",
    "#    print('Finalizado, tarefa: ' + str(ca))\n",
    "\n",
    "#    k_best_dict.update({ca: grid_search_resp.best_estimator_.get_params()['k_best__k']})\n",
    "#print(k_best_dict)\n",
    "\n",
    "#### O resultado deste for é:\n",
    "k_best_dict = {'gender': 5000, \n",
    "               'itf': 3000, \n",
    "               'ap_age': 9000, \n",
    "               'ap_school': 10000, \n",
    "               'ap_religion': 7000, \n",
    "               'ap_politics': 9000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "#k_best_dict = {'gender': 1800,\n",
    "#               'itf': 7800,\n",
    "#               'ap_age': 9800, #9800\n",
    "#               'ap_school': 9800, #9800\n",
    "#               'ap_religion': 7800,\n",
    "#               'ap_politics': 2300}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorized_train = vect.fit_transform(df_ca['text'])\n",
    "text_vectorized_test = vect.transform(df_aa['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = df_aa['id_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 13)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca;accuracy;precision_macro;recall_macro;f1_macro\n",
      "   ca_var        f1  precision    recall  accuracy\n",
      "0  gender  0.866667   0.866667  0.866667       0.9\n",
      "  ca_var        f1  precision    recall  accuracy\n",
      "0    itf  0.784946     0.8125  0.766667      0.85\n",
      "   ca_var        f1  precision    recall  accuracy\n",
      "0  ap_age  0.373333   0.520833  0.416667      0.55\n",
      "      ca_var        f1  precision   recall  accuracy\n",
      "0  ap_school  0.421818     0.4375  0.47619       0.6\n",
      "        ca_var        f1  precision    recall  accuracy\n",
      "0  ap_religion  0.542328   0.627778  0.559259      0.55\n",
      "        ca_var        f1  precision  recall  accuracy\n",
      "0  ap_politics  0.324675   0.309524   0.375      0.45\n"
     ]
    }
   ],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = list(df_aa['id_author'])\n",
    "\n",
    "print('ca;accuracy;precision_macro;recall_macro;f1_macro')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "\n",
    "    k_best = k_best_dict[ca_var]\n",
    "    sel = SelectKBest(k = k_best)\n",
    "    ft = sel.fit(text_vectorized_train, df_ca[ca_var])\n",
    "    train_best = ft.transform(text_vectorized_train)\n",
    "\n",
    "    clf.fit(train_best, df_ca[ca_var])\n",
    "\n",
    "    test_best = ft.transform(text_vectorized_test)\n",
    "\n",
    "    predicted = clf.predict(test_best) #com variavel categorica\n",
    "    predicted_prob = clf.predict_proba(test_best) #com probabilidade de variavel\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_aa[ca_var], predicted)\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))\n",
    "\n",
    "    df_test_ca[ca_var + '_predict'] = predicted\n",
    "    \n",
    "    # probs\n",
    "    df_temp = pd.DataFrame(predicted_prob)\n",
    "    df_temp = df_temp.add_prefix(ca_var + '_')\n",
    "    df_test_ca = df_test_ca.join(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='stratified') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_stratified'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='most_frequent') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_most_frequent'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca_baseline.merge(df_aa[['id_author', 'gender', 'itf', 'ap_age', 'ap_school', 'ap_religion', \n",
    "                                                       'ap_politics']],\n",
    "                          left_on='id_author', right_on='id_author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ca_var        f1  precision  recall  accuracy\n",
      "0  gender  0.428571      0.375     0.5      0.75\n",
      "  ca_var        f1  precision  recall  accuracy\n",
      "0    itf  0.428571      0.375     0.5      0.75\n",
      "   ca_var        f1  precision    recall  accuracy\n",
      "0  ap_age  0.086957       0.05  0.333333      0.15\n",
      "      ca_var        f1  precision    recall  accuracy\n",
      "0  ap_school  0.206897       0.15  0.333333      0.45\n",
      "        ca_var        f1  precision    recall  accuracy\n",
      "0  ap_religion  0.153846        0.1  0.333333       0.3\n",
      "        ca_var        f1  precision    recall  accuracy\n",
      "0  ap_politics  0.190476   0.133333  0.333333       0.4\n"
     ]
    }
   ],
   "source": [
    "#baseline CA\n",
    "#print('ca;f1;precision_macro;recall_macro;accuracy')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_test_ca_baseline[ca_var], df_test_ca_baseline[ca_var + '_dummy_most_frequent'])\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "df_final_aa = df_final[df_final['id_author'].isin(list_authors_aa_selection)]\n",
    "df_final_aa['id_author'] = df_final_aa['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_aa = df_final_aa.merge(df_test_ca, how='left', left_on='id_author', right_on='id_author')\n",
    "df_final_aa = df_final_aa.merge(df[['id_author', 'gender','itf','ap_age','ap_school','ap_religion','ap_politics']], how='left', left_on='id_author', right_on='id_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender</th>\n",
       "      <th>itf</th>\n",
       "      <th>ap_age</th>\n",
       "      <th>ap_school</th>\n",
       "      <th>ap_religion</th>\n",
       "      <th>ap_politics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1079</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>6018</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>6027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>6033</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>6096</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>6102</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>6170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>6285</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>6319</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>6326</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>6329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>6331</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>6337</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>764</th>\n",
       "      <td>6381</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>6394</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>853</th>\n",
       "      <td>6417</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>903</th>\n",
       "      <td>6418</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>6431</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_author  gender  itf  ap_age  ap_school  ap_religion  ap_politics\n",
       "0         1079       1    1       2          2            0            0\n",
       "50        6018       1    1       0          0            1            1\n",
       "122       6027       1    1       0          0            0            0\n",
       "170       6033       1    1       0          0            0            1\n",
       "216         41       1    1       2          2            0            1\n",
       "267       6096       1    1       1          2            1            1\n",
       "311       6102       1    1       1          0            1            0\n",
       "364       6170       1    0       0          0            2            0\n",
       "413       2226       1    1       2          2            2            0\n",
       "459       6285       0    0       2          2            2            1\n",
       "508       6319       1    1       2          2            2            2\n",
       "568       6326       1    1       1          2            2            2\n",
       "611       6329       0    0       2          1            2            2\n",
       "664       6331       1    1       2          1            2            2\n",
       "718       6337       1    1       0          0            1            0\n",
       "764       6381       1    1       2          1            2            0\n",
       "807       6394       1    1       0          0            0            1\n",
       "853       6417       0    0       0          0            1            1\n",
       "903       6418       0    0       0          0            2            1\n",
       "966       6431       0    1       0          1            1            0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.drop_duplicates(subset=['id_author'])[['id_author', 'gender', 'itf', 'ap_age', 'ap_school', 'ap_religion', 'ap_politics']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1009, 42)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "scoring = ['accuracy','precision_macro', 'recall_macro', 'f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(df_train, author, simulation, ca_list, author_list):\n",
    "    ### train\n",
    "    try:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_train[['text'] + ca_list], \n",
    "                                                        df_train['id_author'], \n",
    "                                                    test_size=0.3,random_state=rand.randint(0,900))\n",
    "\n",
    "        pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "        for p in pipelines:\n",
    "            p.fit(x_train['text'], y_train)\n",
    "\n",
    "        predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "        df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "        if 'gender_0' in x_train.columns:\n",
    "            df_train_mix['gender_0'] = x_train['gender_0'].values\n",
    "        if 'gender_1' in x_train.columns:\n",
    "            df_train_mix['gender_1'] = x_train['gender_1'].values\n",
    "        if 'itf_0' in x_train.columns:\n",
    "            df_train_mix['itf_0'] = x_train['itf_0'].values\n",
    "        if 'itf_1' in x_train.columns:\n",
    "            df_train_mix['itf_1'] = x_train['itf_1'].values\n",
    "        if 'ap_age_0' in x_train.columns:\n",
    "            df_train_mix['ap_age_0'] = x_train['ap_age_0'].values\n",
    "        if 'ap_age_1' in x_train.columns:\n",
    "            df_train_mix['ap_age_1'] = x_train['ap_age_1'].values\n",
    "        if 'ap_age_2' in x_train.columns:\n",
    "            df_train_mix['ap_age_2'] = x_train['ap_age_2'].values\n",
    "        if 'ap_school_0' in x_train.columns:\n",
    "            df_train_mix['ap_school_0'] = x_train['ap_school_0'].values\n",
    "        if 'ap_school_1' in x_train.columns:\n",
    "            df_train_mix['ap_school_1'] = x_train['ap_school_1'].values\n",
    "        if 'ap_school_2' in x_train.columns:\n",
    "            df_train_mix['ap_school_2'] = x_train['ap_school_2'].values\n",
    "        if 'ap_religion_0' in x_train.columns:\n",
    "            df_train_mix['ap_religion_0'] = x_train['ap_religion_0'].values\n",
    "        if 'ap_religion_1' in x_train.columns:\n",
    "            df_train_mix['ap_religion_1'] = x_train['ap_religion_1'].values\n",
    "        if 'ap_religion_2' in x_train.columns:\n",
    "            df_train_mix['ap_religion_2'] = x_train['ap_religion_2'].values\n",
    "        if 'ap_politics_0' in x_train.columns:\n",
    "            df_train_mix['ap_politics_0'] = x_train['ap_politics_0'].values\n",
    "        if 'ap_politics_1' in x_train.columns:\n",
    "            df_train_mix['ap_politics_1'] = x_train['ap_politics_1'].values\n",
    "        if 'ap_politics_2' in x_train.columns:\n",
    "            df_train_mix['ap_politics_2'] = x_train['ap_politics_2'].values\n",
    "\n",
    "        if 'gender' in x_train.columns:\n",
    "            df_train_mix['gender'] = x_train['gender'].values\n",
    "        if 'itf' in x_train.columns:\n",
    "            df_train_mix['itf'] = x_train['itf'].values\n",
    "        if 'ap_age' in x_train.columns:\n",
    "            df_train_mix['ap_age'] = x_train['ap_age'].values\n",
    "        if 'ap_school' in x_train.columns:\n",
    "            df_train_mix['ap_school'] = x_train['ap_school'].values\n",
    "        if 'ap_religion' in x_train.columns:\n",
    "            df_train_mix['ap_religion'] = x_train['ap_religion'].values\n",
    "        if 'ap_politics' in x_train.columns:\n",
    "            df_train_mix['ap_politics'] = x_train['ap_politics'].values\n",
    "            \n",
    "        if 'gender_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['gender_dummy_most_frequent'] = x_train['gender_dummy_most_frequent'].values\n",
    "        if 'itf_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['itf_dummy_most_frequent'] = x_train['itf_dummy_most_frequent'].values\n",
    "        if 'ap_age_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['ap_age_dummy_most_frequent'] = x_train['ap_age_dummy_most_frequent'].values\n",
    "        if 'ap_school_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['ap_school_dummy_most_frequent'] = x_train['ap_school_dummy_most_frequent'].values\n",
    "        if 'ap_religion_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['ap_religion_dummy_most_frequent'] = x_train['ap_religion_dummy_most_frequent'].values\n",
    "        if 'ap_politics_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['ap_politics_dummy_most_frequent'] = x_train['ap_politics_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['gender_dummy_stratified'] = x_train['gender_dummy_stratified'].values\n",
    "        if 'itf_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['itf_dummy_stratified'] = x_train['itf_dummy_stratified'].values\n",
    "        if 'ap_age_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['ap_age_dummy_stratified'] = x_train['ap_age_dummy_stratified'].values\n",
    "        if 'ap_school_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['ap_school_dummy_stratified'] = x_train['ap_school_dummy_stratified'].values\n",
    "        if 'ap_religion_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['ap_religion_dummy_stratified'] = x_train['ap_religion_dummy_stratified'].values\n",
    "        if 'ap_politics_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['ap_politics_dummy_stratified'] = x_train['ap_politics_dummy_stratified'].values\n",
    "            \n",
    "        if 'gender_predict' in x_train.columns:\n",
    "            df_train_mix['gender_predict'] = x_train['gender_predict'].values\n",
    "        if 'itf_predict' in x_train.columns:\n",
    "            df_train_mix['itf_predict'] = x_train['itf_predict'].values\n",
    "        if 'ap_age_predict' in x_train.columns:\n",
    "            df_train_mix['ap_age_predict'] = x_train['ap_age_predict'].values\n",
    "        if 'ap_school_predict' in x_train.columns:\n",
    "            df_train_mix['ap_school_predict'] = x_train['ap_school_predict'].values\n",
    "        if 'ap_religion_predict' in x_train.columns:\n",
    "            df_train_mix['ap_religion_predict'] = x_train['ap_religion_predict'].values\n",
    "        if 'ap_politics_predict' in x_train.columns:\n",
    "            df_train_mix['ap_politics_predict'] = x_train['ap_politics_predict'].values\n",
    "\n",
    "        clf_final.fit(df_train_mix, y_train)\n",
    "\n",
    "        #test\n",
    "        predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "        df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "        if 'gender_0' in x_test.columns:\n",
    "            df_test_mix['gender_0'] = x_test['gender_0'].values\n",
    "        if 'gender_1' in x_test.columns:\n",
    "            df_test_mix['gender_1'] = x_test['gender_1'].values\n",
    "        if 'itf_0' in x_test.columns:\n",
    "            df_test_mix['itf_0'] = x_test['itf_0'].values\n",
    "        if 'itf_1' in x_test.columns:\n",
    "            df_test_mix['itf_1'] = x_test['itf_1'].values\n",
    "        if 'ap_age_0' in x_test.columns:\n",
    "            df_test_mix['ap_age_0'] = x_test['ap_age_0'].values\n",
    "        if 'ap_age_1' in x_test.columns:\n",
    "            df_test_mix['ap_age_1'] = x_test['ap_age_1'].values\n",
    "        if 'ap_age_2' in x_test.columns:\n",
    "            df_test_mix['ap_age_2'] = x_test['ap_age_2'].values\n",
    "        if 'ap_school_0' in x_test.columns:\n",
    "            df_test_mix['ap_school_0'] = x_test['ap_school_0'].values\n",
    "        if 'ap_school_1' in x_test.columns:\n",
    "            df_test_mix['ap_school_1'] = x_test['ap_school_1'].values\n",
    "        if 'ap_school_2' in x_test.columns:\n",
    "            df_test_mix['ap_school_2'] = x_test['ap_school_2'].values\n",
    "        if 'ap_religion_0' in x_test.columns:\n",
    "            df_test_mix['ap_religion_0'] = x_test['ap_religion_0'].values\n",
    "        if 'ap_religion_1' in x_test.columns:\n",
    "            df_test_mix['ap_religion_1'] = x_test['ap_religion_1'].values\n",
    "        if 'ap_religion_2' in x_test.columns:\n",
    "            df_test_mix['ap_religion_2'] = x_test['ap_religion_2'].values\n",
    "        if 'ap_politics_0' in x_test.columns:\n",
    "            df_test_mix['ap_politics_0'] = x_test['ap_politics_0'].values\n",
    "        if 'ap_politics_1' in x_test.columns:\n",
    "            df_test_mix['ap_politics_1'] = x_test['ap_politics_1'].values\n",
    "        if 'ap_politics_2' in x_test.columns:\n",
    "            df_test_mix['ap_politics_2'] = x_test['ap_politics_2'].values\n",
    "\n",
    "        if 'gender' in x_test.columns:\n",
    "            df_test_mix['gender'] = x_test['gender'].values\n",
    "        if 'itf' in x_test.columns:\n",
    "            df_test_mix['itf'] = x_test['itf'].values\n",
    "        if 'ap_age' in x_test.columns:\n",
    "            df_test_mix['ap_age'] = x_test['ap_age'].values\n",
    "        if 'ap_school' in x_test.columns:\n",
    "            df_test_mix['ap_school'] = x_test['ap_school'].values\n",
    "        if 'ap_religion' in x_test.columns:\n",
    "            df_test_mix['ap_religion'] = x_test['ap_religion'].values\n",
    "        if 'ap_politics' in x_test.columns:\n",
    "            df_test_mix['ap_politics'] = x_test['ap_politics'].values\n",
    "            \n",
    "        if 'gender_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['gender_dummy_most_frequent'] = x_test['gender_dummy_most_frequent'].values\n",
    "        if 'itf_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['itf_dummy_most_frequent'] = x_test['itf_dummy_most_frequent'].values\n",
    "        if 'ap_age_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['ap_age_dummy_most_frequent'] = x_test['ap_age_dummy_most_frequent'].values\n",
    "        if 'ap_school_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['ap_school_dummy_most_frequent'] = x_test['ap_school_dummy_most_frequent'].values\n",
    "        if 'ap_religion_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['ap_religion_dummy_most_frequent'] = x_test['ap_religion_dummy_most_frequent'].values\n",
    "        if 'ap_politics_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['ap_politics_dummy_most_frequent'] = x_test['ap_politics_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['gender_dummy_stratified'] = x_test['gender_dummy_stratified'].values\n",
    "        if 'itf_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['itf_dummy_stratified'] = x_test['itf_dummy_stratified'].values\n",
    "        if 'ap_age_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['ap_age_dummy_stratified'] = x_test['ap_age_dummy_stratified'].values\n",
    "        if 'ap_school_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['ap_school_dummy_stratified'] = x_test['ap_school_dummy_stratified'].values\n",
    "        if 'ap_religion_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['ap_religion_dummy_stratified'] = x_test['ap_religion_dummy_stratified'].values\n",
    "        if 'ap_politics_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['ap_politics_dummy_stratified'] = x_test['ap_politics_dummy_stratified'].values\n",
    "\n",
    "        if 'gender_predict' in x_test.columns:\n",
    "            df_test_mix['gender_predict'] = x_test['gender_predict'].values\n",
    "        if 'itf_predict' in x_test.columns:\n",
    "            df_test_mix['itf_predict'] = x_test['itf_predict'].values\n",
    "        if 'ap_age_predict' in x_test.columns:\n",
    "            df_test_mix['ap_age_predict'] = x_test['ap_age_predict'].values\n",
    "        if 'ap_school_predict' in x_test.columns:\n",
    "            df_test_mix['ap_school_predict'] = x_test['ap_school_predict'].values\n",
    "        if 'ap_religion_predict' in x_test.columns:\n",
    "            df_test_mix['ap_religion_predict'] = x_test['ap_religion_predict'].values\n",
    "        if 'ap_politics_predict' in x_test.columns:\n",
    "            df_test_mix['ap_politics_predict'] = x_test['ap_politics_predict'].values\n",
    "            \n",
    "        test_pred = clf_final.predict(df_test_mix)\n",
    "\n",
    "        f1, precision, recall, accuracy = eval_measures(y_test, test_pred)\n",
    "\n",
    "        return pd.DataFrame(data=[[author, f1, precision, recall, accuracy, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])\n",
    "    except Exception as e:\n",
    "        #print('erro na simulacao')\n",
    "        print(traceback.print_exc())\n",
    "        return pd.DataFrame(data=[[0.0, 0.0, 0.0, 0.0, 0.0, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list_11 = []\n",
    "\n",
    "#individuais\n",
    "ca_list_02 = ['gender']\n",
    "ca_list_03 = ['itf']\n",
    "ca_list_04 = ['ap_age']\n",
    "ca_list_05 = ['ap_school']\n",
    "ca_list_06 = ['ap_religion']\n",
    "ca_list_07 = ['ap_politics']\n",
    "\n",
    "ca_list_12 = ['gender_predict']\n",
    "ca_list_13 = ['itf_predict']\n",
    "ca_list_14 = ['ap_age_predict']\n",
    "ca_list_15 = ['ap_school_predict']\n",
    "ca_list_16 = ['ap_religion_predict']\n",
    "ca_list_17 = ['ap_politics_predict']\n",
    "\n",
    "ca_list_221 = ['gender_dummy_stratified']\n",
    "ca_list_231 = ['itf_dummy_stratified']\n",
    "ca_list_241 = ['ap_age_dummy_stratified']\n",
    "ca_list_251 = ['ap_school_dummy_stratified']\n",
    "ca_list_261 = ['ap_religion_dummy_stratified']\n",
    "ca_list_271 = ['ap_politics_dummy_stratified']\n",
    "\n",
    "ca_list_222 = ['gender_dummy_most_frequent']\n",
    "ca_list_232 = ['itf_dummy_most_frequent']\n",
    "ca_list_242 = ['ap_age_dummy_most_frequent']\n",
    "ca_list_252 = ['ap_school_dummy_most_frequent']\n",
    "ca_list_262 = ['ap_religion_dummy_most_frequent']\n",
    "ca_list_272 = ['ap_politics_dummy_most_frequent']\n",
    "\n",
    "ca_list_32 = ['gender_0', 'gender_1']\n",
    "ca_list_33 = ['itf_0', 'itf_1']\n",
    "ca_list_34 = ['ap_age_0', 'ap_age_1', 'ap_age_2']\n",
    "ca_list_35 = ['ap_school_0', 'ap_school_1', 'ap_school_2']\n",
    "ca_list_36 = ['ap_religion_0', 'ap_religion_1', 'ap_religion_2']\n",
    "ca_list_37 = ['ap_politics_0', 'ap_politics_1', 'ap_politics_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "#rand.shuffle(list_authors_aa_selection)\n",
    "#author_list_filter = list_authors_aa_selection[:2]\n",
    "\n",
    "#run_simulation(df_filter, 1, 1, ca_list_36, author_list_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing simulation number: 0 data: 29/04/2020 15:03:42\n",
      "Executing simulation number: 1 data: 29/04/2020 15:06:26\n",
      "Executing simulation number: 2 data: 29/04/2020 15:09:27\n",
      "Executing simulation number: 3 data: 29/04/2020 15:14:44\n",
      "Executing simulation number: 4 data: 29/04/2020 15:30:19\n"
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 20):\n",
    "    rand.shuffle(list_authors_aa_selection)\n",
    "\n",
    "    now = datetime.now()\n",
    "\n",
    "    print(\"Executing simulation number: \" + str(i) + \" data: \" + str(now.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "\n",
    "    for j in range(2, limit_authors_aa_selection + 2, 2):\n",
    "        \n",
    "        author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "        df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "        \n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_11, author_list_filter)) # baseline\n",
    "        \n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_07, author_list_filter)) # predict\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_12, author_list_filter)) # predict\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_13, author_list_filter)) # predict\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_14, author_list_filter)) # predict\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_15, author_list_filter)) # predict\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_16, author_list_filter)) # predict\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_17, author_list_filter)) # predict\n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_271, author_list_filter)) # baseline\n",
    "        \n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_222, author_list_filter)) # most_frequent\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_232, author_list_filter)) # most_frequent\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_242, author_list_filter)) # most_frequent\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_252, author_list_filter)) # most_frequent\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_262, author_list_filter)) # most_frequent\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_272, author_list_filter)) # most_frequent\n",
    "        \n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_32, author_list_filter)) # prob\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_33, author_list_filter)) # prob\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_34, author_list_filter)) # prob\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_35, author_list_filter)) # prob\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_36, author_list_filter)) # prob\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_37, author_list_filter)) # prob\n",
    "        \n",
    "\n",
    "    df_metrics.to_excel(os.path.join('output', 'kbest_proprio_' + str(now.strftime(\"%d_%m_%Y__%H_%M_%S\")) + \".xlsx\"))\n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_train, j, i, ca_list))\n",
    "        #print(str(authors_shuffle[:j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste McNemar's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mcnemar(j, ca_classf_list_1, ca_classf_list_2):\n",
    "\n",
    "    clf_final_classif_1 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "    clf_final_classif_2 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "    author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "    df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_1], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_1.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred = clf_final_classif_1.predict(df_test_mix)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_2], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_2.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred2 = clf_final_classif_2.predict(df_test_mix)\n",
    "\n",
    "    df_mcnemar_test = pd.DataFrame()\n",
    "    df_mcnemar_test['model_pred_classif_1'] = test_pred\n",
    "    df_mcnemar_test['model_pred_classif_2'] = test_pred2\n",
    "    df_mcnemar_test['original_label'] = y_test.values\n",
    "\n",
    "    df_mcnemar_test['classf_1'] = np.where(df_mcnemar_test['model_pred_classif_1']==df_mcnemar_test['original_label'], 0, 1)\n",
    "    df_mcnemar_test['classf_2'] = np.where(df_mcnemar_test['model_pred_classif_2']==df_mcnemar_test['original_label'], 0, 1)\n",
    "\n",
    "    print(\"classf_1 acc: \" + str(1-sum(df_mcnemar_test['classf_1'])/len(df_mcnemar_test)))\n",
    "    print(\"classf_2 acc: \" + str(1-sum(df_mcnemar_test['classf_2'])/len(df_mcnemar_test)))\n",
    "\n",
    "    data_crosstab = pd.crosstab(df_mcnemar_test['classf_1'],  \n",
    "                                df_mcnemar_test['classf_2'], \n",
    "                                margins = False) \n",
    "    print(data_crosstab)\n",
    "\n",
    "    \n",
    "    count_contingence_table = np.where(data_crosstab>25, 1, 0).sum()\n",
    "    \n",
    "    if count_contingence_table==4:\n",
    "        result = mcnemar(data_crosstab, exact=False, correction=True)\n",
    "        print(\"Todos os termos maiores que 25\")\n",
    "    else:\n",
    "        print(\"Algum termo menor que 25\")\n",
    "        result = mcnemar(data_crosstab, exact=True)\n",
    "\n",
    "    print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "    # interpret the p-value\n",
    "    alpha = 0.05\n",
    "    if result.pvalue > alpha:\n",
    "        print('Same proportions of errors (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.2838283828382838\n",
      "classf_2 acc: 0.4158415841584159\n",
      "classf_2   0    1\n",
      "classf_1         \n",
      "0         85    1\n",
      "1         41  176\n",
      "Algum termo menor que 25\n",
      "statistic=1.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.2838283828382838\n",
      "classf_2 acc: 0.29702970297029707\n",
      "classf_2   0    1\n",
      "classf_1         \n",
      "0         86    0\n",
      "1          4  213\n",
      "Algum termo menor que 25\n",
      "statistic=0.000, p-value=0.125\n",
      "Same proportions of errors (fail to reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.4158415841584159\n",
      "classf_2 acc: 0.29702970297029707\n",
      "classf_2   0    1\n",
      "classf_1         \n",
      "0         89   37\n",
      "1          1  176\n",
      "Algum termo menor que 25\n",
      "statistic=1.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_16, ca_list_36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
