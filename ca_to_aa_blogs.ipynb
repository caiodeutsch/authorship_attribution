{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import itertools\n",
    "from datetime import datetime\n",
    "import traceback\n",
    "import pickle\n",
    "import warnings\n",
    "\n",
    "#model valuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import random as rand\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import normalize, Normalizer, MaxAbsScaler, MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linux-4.4.0-1112-aws-x86_64-with-debian-stretch-sid\n",
      "NumPy 1.14.3\n",
      "SciPy 1.1.0\n",
      "Scikit-Learn 0.19.1\n"
     ]
    }
   ],
   "source": [
    "import platform\n",
    "import scipy\n",
    "import sklearn\n",
    "print(platform.platform())\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"SciPy\", scipy.__version__)\n",
    "print(\"Scikit-Learn\", sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class DenseTransformer(BaseEstimator):\n",
    "    def __init__(self, return_copy=True):\n",
    "        self.return_copy = return_copy\n",
    "        self.is_fitted = False\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        if issparse(X):\n",
    "            return X.toarray()\n",
    "        elif self.return_copy:\n",
    "            return X.copy()\n",
    "        else:\n",
    "            return X\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.is_fitted = True\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from scipy.sparse import issparse\n",
    "\n",
    "class ObfuscationTransformer(BaseEstimator):\n",
    "    def __init__(self,re_from=r'(\\b)(\\w{0,2})\\w+(\\w{1,3})(\\b)', re_to=r'\\1\\2XX\\3\\4', return_copy=True):\n",
    "        self.re_from = re_from\n",
    "        self.re_to = re_to\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X = np.array(X).copy();\n",
    "        for i in range(len(X)):\n",
    "            X[i] = re.sub(self.re_from,self.re_to, X[i])\n",
    "        \n",
    "        return X;\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.transform(X=X, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def eval_measures(gt, pred):\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter('ignore')\n",
    "        f1 = f1_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        precision = precision_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        recall = recall_score(gt,\n",
    "                  pred,\n",
    "                  labels=list(set(gt)),\n",
    "                  average='macro')\n",
    "        accuracy = accuracy_score(gt,\n",
    "                  pred)\n",
    "\n",
    "    return f1,precision,recall,accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineCharacter = Pipeline([\n",
    "    ('vect',   TfidfVectorizer(\n",
    "            analyzer='char',\n",
    "            min_df=0.05,\n",
    "            max_df=1.0,\n",
    "            ngram_range=(2,5),\n",
    "            lowercase=False,\n",
    "            norm='l2',\n",
    "            sublinear_tf=True)),\n",
    "    ('dense',  DenseTransformer()),\n",
    "    ('scaler', MaxAbsScaler()),\n",
    "    ('transf', PCA(0.999)),\n",
    "    ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "])\n",
    "\n",
    "pipelineObfuscator = Pipeline([\n",
    "        ('obs',ObfuscationTransformer(re_from=r'\\w',re_to='x')),\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='char',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(2,5),\n",
    "                lowercase=False,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0,multi_class='multinomial', solver='newton-cg')),\n",
    "    ])\n",
    "\n",
    "pipelineWord = Pipeline([\n",
    "        ('vect',   TfidfVectorizer(\n",
    "                analyzer='word',\n",
    "                min_df=0.05,\n",
    "                max_df=1.0,\n",
    "                ngram_range=(1,3),\n",
    "                lowercase=True,\n",
    "                norm='l2',\n",
    "                sublinear_tf=True)),\n",
    "        ('dense',  DenseTransformer()),\n",
    "        ('scaler', MaxAbsScaler()),\n",
    "        ('transf', PCA(0.999)),\n",
    "        ('clf', LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')),\n",
    "    ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('/home/ubuntu/lab/Experimentos/experimento_3_corpus_blogs')\n",
    "input_file = os.path.join('input', 'output_concat.pickle')\n",
    "\n",
    "with open(input_file, 'rb') as handle:\n",
    "    df = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'gender_final': 'gender',\n",
    "                       'age_final': 'ap_age',\n",
    "                       'post_concat': 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['id_author'] = df['filename'].str.split('.', expand=True)[0]\n",
    "del df['filename']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['count_delimiter'] = df['text'].str.split(\"\\|<->\\|\").apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final_statistics = df.copy()\n",
    "df_final_statistics['number_of_words'] = df['text'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>gender</th>\n",
       "      <th>ap_age</th>\n",
       "      <th>id_author</th>\n",
       "      <th>count_delimiter</th>\n",
       "      <th>number_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>well, everyone got up and going this morning. ...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1000331</td>\n",
       "      <td>13</td>\n",
       "      <td>1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yeah, sorry for not writing for a whole there...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1000866</td>\n",
       "      <td>771</td>\n",
       "      <td>126790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cupid,please hear my cry, cupid, please let yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1004904</td>\n",
       "      <td>52</td>\n",
       "      <td>3536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>and did i mention that i no longer have to dea...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1005076</td>\n",
       "      <td>85</td>\n",
       "      <td>4337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b-logs: the business blogs paradox    urllink...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1005545</td>\n",
       "      <td>80</td>\n",
       "      <td>16310</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  gender  ap_age  \\\n",
       "0  well, everyone got up and going this morning. ...       0       2   \n",
       "1   yeah, sorry for not writing for a whole there...       0       0   \n",
       "2  cupid,please hear my cry, cupid, please let yo...       1       1   \n",
       "3  and did i mention that i no longer have to dea...       0       1   \n",
       "4   b-logs: the business blogs paradox    urllink...       1       1   \n",
       "\n",
       "  id_author  count_delimiter  number_of_words  \n",
       "0   1000331               13             1127  \n",
       "1   1000866              771           126790  \n",
       "2   1004904               52             3536  \n",
       "3   1005076               85             4337  \n",
       "4   1005545               80            16310  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_statistics.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de unidades: 918298\n",
      "Total de palavras: 133727748\n",
      "Total de palavras/unidade: 145.62565528837044\n"
     ]
    }
   ],
   "source": [
    "print(\"Total de unidades: \" + str(sum(df_final_statistics['count_delimiter'])))\n",
    "print(\"Total de palavras: \" + str(sum(df_final_statistics['number_of_words'])))\n",
    "print(\"Total de palavras/unidade: \" + str(sum(df_final_statistics['number_of_words'])/sum(df_final_statistics['count_delimiter'])))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## selecao de autores com mais textos\n",
    "limit_authors_aa_selection = 20\n",
    "#list_authors_aa_selection = list(df_final['id_author'].value_counts()[:limit_authors_aa_selection].index)\n",
    "list_authors_aa_selection = list(df.sort_values(by='count_delimiter', ascending=False)[:limit_authors_aa_selection]['id_author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divisao de bases\n",
    "df_aa = df[df['id_author'].isin(list_authors_aa_selection)]\n",
    "df_ca = df[~df['id_author'].isin(list_authors_aa_selection)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_kbest = Pipeline([\n",
    "    ('vect', TfidfVectorizer()), \n",
    "    ('k_best', SelectKBest(f_classif)),\n",
    "    ('clf', LogisticRegression(random_state=42, n_jobs=6))\n",
    "])\n",
    "    \n",
    "parameters_kbest = {    \n",
    "    'k_best__k': (range(3000,20000,1000))\n",
    "}\n",
    "\n",
    "grid_search_resp = GridSearchCV(pipeline_kbest,\n",
    "                               parameters_kbest,\n",
    "                               cv=2,\n",
    "                               scoring='f1_macro',\n",
    "                               n_jobs=4,\n",
    "                               verbose=10\n",
    "                               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ca_list = ['gender', 'ap_age']\n",
    "ca_list = ['ap_age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k_best_dict = {}\n",
    "\n",
    "#for ca in ca_list:\n",
    "   \n",
    "    #warnings.filterwarnings(\"ignore\")\n",
    "#    grid_search_resp.fit(df_ca['text'], df_ca[ca])\n",
    "#    print('Finalizado, tarefa: ' + str(ca))\n",
    "\n",
    "#    k_best_dict.update({ca: grid_search_resp.best_estimator_.get_params()['k_best__k']})\n",
    "#print(k_best_dict)\n",
    "\n",
    "#### O resultado deste for Ã©:\n",
    "k_best_dict = {'gender': 17000,\n",
    "               'ap_age': 19000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'gender': 17000, 'ap_age': 19000}\n"
     ]
    }
   ],
   "source": [
    "print(k_best_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = TfidfVectorizer()\n",
    "clf = LogisticRegression(class_weight='balanced')\n",
    "\n",
    "# estimado\n",
    "#k_best_dict = {'gender': 1800,\n",
    "#               'ap_age': 9800}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vectorized_train = vect.fit_transform(df_ca['text'])\n",
    "text_vectorized_test = vect.transform(df_aa['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = df_aa['id_author']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['1000331', '1000866', '1004904', ..., '998237', '998966', '999503'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df_ca.head()\n",
    "#df_ca['text'].iloc[0]\n",
    "#df_ca.shape\n",
    "df_ca['id_author'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca;accuracy;precision_macro;recall_macro;f1_macro\n",
      "   ca_var        f1  precision    recall  accuracy\n",
      "0  gender  0.649123   0.666667  0.661616      0.65\n",
      "   ca_var       f1  precision    recall  accuracy\n",
      "0  ap_age  0.76122   0.731481  0.814815      0.75\n"
     ]
    }
   ],
   "source": [
    "df_test_ca = pd.DataFrame()\n",
    "df_test_ca['id_author'] = list(df_aa['id_author'])\n",
    "\n",
    "print('ca;accuracy;precision_macro;recall_macro;f1_macro')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "\n",
    "    k_best = k_best_dict[ca_var]\n",
    "    sel = SelectKBest(k = k_best)\n",
    "    ft = sel.fit(text_vectorized_train, df_ca[ca_var])\n",
    "    train_best = ft.transform(text_vectorized_train)\n",
    "\n",
    "    clf.fit(train_best, df_ca[ca_var])\n",
    "\n",
    "    test_best = ft.transform(text_vectorized_test)\n",
    "\n",
    "    predicted = clf.predict(test_best) #com variavel categorica\n",
    "    predicted_prob = clf.predict_proba(test_best) #com probabilidade de variavel\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_aa[ca_var], predicted)\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))\n",
    "\n",
    "    df_test_ca[ca_var + '_predict'] = predicted\n",
    "    \n",
    "    # probs\n",
    "    df_temp = pd.DataFrame(predicted_prob)\n",
    "    df_temp = df_temp.add_prefix(ca_var + '_')\n",
    "    df_test_ca = df_test_ca.join(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='stratified') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_stratified'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_dummy = DummyClassifier(strategy='most_frequent') #most_frequent, #stratified\n",
    "for ca_var in k_best_dict:\n",
    "    clf_dummy.fit(df_ca['id_author'].values.reshape(-1,1), df_ca[ca_var].values)\n",
    "    predicted = clf_dummy.predict(df_aa['id_author'].values.reshape(-1,1))\n",
    "    df_test_ca[ca_var + '_dummy_most_frequent'] = predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca.copy() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca_baseline = df_test_ca_baseline.merge(df_aa[['id_author', 'gender', 'ap_age']],\n",
    "                          left_on='id_author', right_on='id_author', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ca_var        f1  precision  recall  accuracy\n",
      "0  gender  0.310345      0.225     0.5      0.45\n",
      "   ca_var        f1  precision    recall  accuracy\n",
      "0  ap_age  0.060606   0.033333  0.333333       0.1\n"
     ]
    }
   ],
   "source": [
    "#baseline CA\n",
    "#print('ca;f1;precision_macro;recall_macro;accuracy')\n",
    "\n",
    "for ca_var in k_best_dict:\n",
    "    \n",
    "    f1, precision, recall, accuracy = eval_measures(df_test_ca_baseline[ca_var], df_test_ca_baseline[ca_var + '_dummy_most_frequent'])\n",
    "\n",
    "    print(pd.DataFrame(data=[[ca_var, f1, precision, recall, accuracy]], \n",
    "             columns=['ca_var', 'f1', 'precision', 'recall', 'accuracy']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(df_aa)):\n",
    "    text_list = df_aa['text'].iloc[i].split('|<->|')\n",
    "    author_list = [df_aa['id_author'].iloc[i]]*len(text_list)\n",
    "    df_inter = pd.DataFrame(data=[text_list, author_list]).T\n",
    "    df_inter = df_inter.rename(columns={0: 'text', 1: 'id_author'})\n",
    "    \n",
    "    df_final = df_final.append(df_inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_final = df_final[df_final['text'].apply(len)>20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_aa = df_final[df_final['id_author'].isin(list_authors_aa_selection)]\n",
    "df_final_aa['id_author'] = df_final_aa['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_ca['id_author'] = df_test_ca['id_author'].astype(int)\n",
    "df['id_author'] = df['id_author'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_aa = df_final_aa.merge(df_test_ca, how='left', left_on='id_author', right_on='id_author')\n",
    "df_final_aa = df_final_aa.merge(df[['id_author', 'gender','ap_age']], how='left', left_on='id_author', right_on='id_author')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_final = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "scoring = ['accuracy','precision_macro', 'recall_macro', 'f1_macro']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32652, 15)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_author</th>\n",
       "      <th>gender</th>\n",
       "      <th>ap_age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>106651</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>1417798</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2290</th>\n",
       "      <td>1470319</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3405</th>\n",
       "      <td>1472995</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4520</th>\n",
       "      <td>1596188</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5506</th>\n",
       "      <td>1784456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7282</th>\n",
       "      <td>1975546</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9523</th>\n",
       "      <td>2200026</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10649</th>\n",
       "      <td>271835</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11806</th>\n",
       "      <td>2866266</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13014</th>\n",
       "      <td>303162</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15126</th>\n",
       "      <td>449628</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19345</th>\n",
       "      <td>470861</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20173</th>\n",
       "      <td>576311</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22478</th>\n",
       "      <td>589736</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24709</th>\n",
       "      <td>734562</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26945</th>\n",
       "      <td>780903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28282</th>\n",
       "      <td>831241</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29292</th>\n",
       "      <td>907450</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30584</th>\n",
       "      <td>942828</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id_author  gender  ap_age\n",
       "0         106651       1       1\n",
       "1245     1417798       0       2\n",
       "2290     1470319       0       1\n",
       "3405     1472995       0       1\n",
       "4520     1596188       0       2\n",
       "5506     1784456       0       0\n",
       "7282     1975546       0       1\n",
       "9523     2200026       1       2\n",
       "10649     271835       1       1\n",
       "11806    2866266       1       0\n",
       "13014     303162       0       2\n",
       "15126     449628       1       2\n",
       "19345     470861       1       1\n",
       "20173     576311       0       2\n",
       "22478     589736       1       2\n",
       "24709     734562       0       1\n",
       "26945     780903       1       1\n",
       "28282     831241       0       2\n",
       "29292     907450       1       1\n",
       "30584     942828       0       2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_aa.drop_duplicates(subset=['id_author'])[['id_author', 'gender', 'ap_age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation(df_train, author, simulation, ca_list, author_list):\n",
    "    ### train\n",
    "    try:\n",
    "        x_train, x_test, y_train, y_test = train_test_split(df_train[['text'] + ca_list], \n",
    "                                                        df_train['id_author'], \n",
    "                                                    test_size=0.3,random_state=rand.randint(0,900))\n",
    "\n",
    "        pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "        for p in pipelines:\n",
    "            p.fit(x_train['text'], y_train)\n",
    "\n",
    "        predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "        df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "        if 'gender_0' in x_train.columns:\n",
    "            df_train_mix['gender_0'] = x_train['gender_0'].values\n",
    "        if 'gender_1' in x_train.columns:\n",
    "            df_train_mix['gender_1'] = x_train['gender_1'].values\n",
    "        if 'ap_age_0' in x_train.columns:\n",
    "            df_train_mix['ap_age_0'] = x_train['ap_age_0'].values\n",
    "        if 'ap_age_1' in x_train.columns:\n",
    "            df_train_mix['ap_age_1'] = x_train['ap_age_1'].values\n",
    "        if 'ap_age_2' in x_train.columns:\n",
    "            df_train_mix['ap_age_2'] = x_train['ap_age_2'].values\n",
    "\n",
    "        if 'gender' in x_train.columns:\n",
    "            df_train_mix['gender'] = x_train['gender'].values\n",
    "        if 'ap_age' in x_train.columns:\n",
    "            df_train_mix['ap_age'] = x_train['ap_age'].values\n",
    "            \n",
    "        if 'gender_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['gender_dummy_most_frequent'] = x_train['gender_dummy_most_frequent'].values\n",
    "        if 'ap_age_dummy_most_frequent' in x_train.columns:\n",
    "            df_train_mix['ap_age_dummy_most_frequent'] = x_train['ap_age_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['gender_dummy_stratified'] = x_train['gender_dummy_stratified'].values\n",
    "        if 'ap_age_dummy_stratified' in x_train.columns:\n",
    "            df_train_mix['ap_age_dummy_stratified'] = x_train['ap_age_dummy_stratified'].values\n",
    "            \n",
    "        if 'gender_predict' in x_train.columns:\n",
    "            df_train_mix['gender_predict'] = x_train['gender_predict'].values\n",
    "        if 'ap_age_predict' in x_train.columns:\n",
    "            df_train_mix['ap_age_predict'] = x_train['ap_age_predict'].values\n",
    "\n",
    "        clf_final.fit(df_train_mix, y_train)\n",
    "\n",
    "        #test\n",
    "        predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "        df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "        if 'gender_0' in x_test.columns:\n",
    "            df_test_mix['gender_0'] = x_test['gender_0'].values\n",
    "        if 'gender_1' in x_test.columns:\n",
    "            df_test_mix['gender_1'] = x_test['gender_1'].values\n",
    "        if 'ap_age_0' in x_test.columns:\n",
    "            df_test_mix['ap_age_0'] = x_test['ap_age_0'].values\n",
    "        if 'ap_age_1' in x_test.columns:\n",
    "            df_test_mix['ap_age_1'] = x_test['ap_age_1'].values\n",
    "        if 'ap_age_2' in x_test.columns:\n",
    "            df_test_mix['ap_age_2'] = x_test['ap_age_2'].values\n",
    "\n",
    "        if 'gender' in x_test.columns:\n",
    "            df_test_mix['gender'] = x_test['gender'].values\n",
    "        if 'ap_age' in x_test.columns:\n",
    "            df_test_mix['ap_age'] = x_test['ap_age'].values\n",
    "            \n",
    "        if 'gender_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['gender_dummy_most_frequent'] = x_test['gender_dummy_most_frequent'].values\n",
    "        if 'ap_age_dummy_most_frequent' in x_test.columns:\n",
    "            df_test_mix['ap_age_dummy_most_frequent'] = x_test['ap_age_dummy_most_frequent'].values\n",
    "\n",
    "        if 'gender_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['gender_dummy_stratified'] = x_test['gender_dummy_stratified'].values\n",
    "        if 'ap_age_dummy_stratified' in x_test.columns:\n",
    "            df_test_mix['ap_age_dummy_stratified'] = x_test['ap_age_dummy_stratified'].values\n",
    "\n",
    "        if 'gender_predict' in x_test.columns:\n",
    "            df_test_mix['gender_predict'] = x_test['gender_predict'].values\n",
    "        if 'ap_age_predict' in x_test.columns:\n",
    "            df_test_mix['ap_age_predict'] = x_test['ap_age_predict'].values\n",
    "            \n",
    "        test_pred = clf_final.predict(df_test_mix)\n",
    "\n",
    "        f1, precision, recall, accuracy = eval_measures(y_test, test_pred)\n",
    "        print(\"Executado para : \" + str(author) + ' autores - ' + str(now.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "\n",
    "        return pd.DataFrame(data=[[author, f1, precision, recall, accuracy, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])\n",
    "    except Exception as e:\n",
    "        #print('erro na simulacao')\n",
    "        print(traceback.print_exc())\n",
    "        return pd.DataFrame(data=[[0.0, 0.0, 0.0, 0.0, 0.0, simulation, str(ca_list), str(author_list)]], \n",
    "                 columns=['autors_selected', 'f1', 'precision', 'recall', 'accuracy', 'simulation', 'ca_list', 'author_list'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ca_list_11 = []\n",
    "\n",
    "#individuais\n",
    "ca_list_02 = ['gender']\n",
    "ca_list_04 = ['ap_age']\n",
    "\n",
    "ca_list_12 = ['gender_predict']\n",
    "ca_list_14 = ['ap_age_predict']\n",
    "\n",
    "ca_list_221 = ['gender_dummy_stratified']\n",
    "ca_list_241 = ['ap_age_dummy_stratified']\n",
    "\n",
    "ca_list_222 = ['gender_dummy_most_frequent']\n",
    "ca_list_242 = ['ap_age_dummy_most_frequent']\n",
    "\n",
    "ca_list_32 = ['gender_0', 'gender_1']\n",
    "ca_list_34 = ['ap_age_0', 'ap_age_1', 'ap_age_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "#rand.shuffle(list_authors_aa_selection)\n",
    "#author_list_filter = list_authors_aa_selection[:2]\n",
    "\n",
    "#run_simulation(df_filter, 1, 1, ca_list_36, author_list_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing simulation number: 0 data: 04/04/2020 20:44:22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 2 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 4 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 6 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 8 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executado para : 10 autores - 04_04_2020__20_44_22\n",
      "Executing simulation number: 1 data: 04/04/2020 22:36:26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 2 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 4 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 6 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 8 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executado para : 10 autores - 04_04_2020__22_36_26\n",
      "Executing simulation number: 2 data: 05/04/2020 02:06:10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 2 autores - 05_04_2020__02_06_10\n",
      "Executado para : 4 autores - 05_04_2020__02_06_10\n",
      "Executado para : 4 autores - 05_04_2020__02_06_10\n",
      "Executado para : 4 autores - 05_04_2020__02_06_10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-101-024e8cd48c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_list_02\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_list_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_list_12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_list_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_list_221\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_list_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_list_222\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_list_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mdf_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_simulation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_filter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mca_list_32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor_list_filter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# baseline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-98-c2607337c459>\u001b[0m in \u001b[0;36mrun_simulation\u001b[0;34m(df_train, author, simulation, ca_list, author_list)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mpipelines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpipelineCharacter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineObfuscator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpipelineWord\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpredict_text_train_aa_mix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mThis\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \"\"\"\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_final_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    211\u001b[0m                 Xt, fitted_transformer = fit_transform_one_cached(\n\u001b[1;32m    212\u001b[0m                     \u001b[0mcloned_transformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m                     **fit_params_steps[name])\n\u001b[0m\u001b[1;32m    214\u001b[0m                 \u001b[0;31m# Replace the transformer of the step with the fitted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0;31m# transformer. This is necessary when loading the transformer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/memory.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcall_and_shelve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/pipeline.py\u001b[0m in \u001b[0;36m_fit_transform_one\u001b[0;34m(transformer, weight, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    579\u001b[0m                        **fit_params):\n\u001b[1;32m    580\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtransformer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'fit_transform'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 581\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    582\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1379\u001b[0m             \u001b[0mTf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mweighted\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mterm\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m         \"\"\"\n\u001b[0;32m-> 1381\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1383\u001b[0m         \u001b[0;31m# X is already a transformed view of raw_documents so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 869\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/feature_extraction/text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    796\u001b[0m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                         \u001b[0mfeature_counter\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;31m# Ignore out-of-vocabulary items for fixed_vocab=True\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df_metrics = pd.DataFrame()\n",
    "\n",
    "for i in range(0, 20):\n",
    "    rand.shuffle(list_authors_aa_selection)\n",
    "\n",
    "    now = datetime.now()\n",
    "\n",
    "    print(\"Executing simulation number: \" + str(i) + \" data: \" + str(now.strftime(\"%d/%m/%Y %H:%M:%S\")))\n",
    "\n",
    "    for j in range(2, limit_authors_aa_selection -10 + 2, 2):\n",
    "        \n",
    "        author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "        df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "        \n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_11, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_02, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_12, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_221, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_222, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_32, author_list_filter)) # baseline\n",
    "\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_04, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_14, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_241, author_list_filter)) # baseline\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_242, author_list_filter)) # baseline\n",
    "        df_metrics = df_metrics.append(run_simulation(df_filter, j, i, ca_list_34, author_list_filter)) # baseline\n",
    "    df_metrics.to_excel(os.path.join('output', 'kbest_proprio_' + str(now.strftime(\"%d_%m_%Y__%H_%M_%S\")) + \".xlsx\"))\n",
    "\n",
    "        #df_metrics = df_metrics.append(run_simulation(df_train, j, i, ca_list))\n",
    "        #print(str(authors_shuffle[:j]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste McNemar's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.contingency_tables import mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_mcnemar(j, ca_classf_list_1, ca_classf_list_2):\n",
    "\n",
    "    clf_final_classif_1 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "    clf_final_classif_2 = LogisticRegression(random_state=42, multi_class='multinomial', solver='newton-cg')\n",
    "\n",
    "    author_list_filter = list_authors_aa_selection[:j]\n",
    "\n",
    "    df_filter = df_final_aa[df_final_aa['id_author'].isin(author_list_filter)]\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_1], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_1.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_1:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred = clf_final_classif_1.predict(df_test_mix)\n",
    "\n",
    "    x_train, x_test, y_train, y_test = train_test_split(df_filter[['text'] + ca_classf_list_2], \n",
    "                                                    df_filter['id_author'], \n",
    "                                                test_size=0.3,random_state=42)\n",
    "\n",
    "    pipelines = [pipelineCharacter, pipelineObfuscator, pipelineWord]\n",
    "\n",
    "    for p in pipelines:\n",
    "        p.fit(x_train['text'], y_train)\n",
    "\n",
    "    predict_text_train_aa_mix = np.hstack([p.predict_proba(x_train['text']) for p in pipelines])\n",
    "\n",
    "    df_train_mix = pd.DataFrame(data=predict_text_train_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_train_mix[ca] = x_train[ca].values\n",
    "\n",
    "    clf_final_classif_2.fit(df_train_mix, y_train)\n",
    "\n",
    "    predict_text_test_aa_mix = np.hstack([p.predict_proba(x_test['text']) for p in pipelines])\n",
    "    df_test_mix = pd.DataFrame(data=predict_text_test_aa_mix)\n",
    "\n",
    "    for ca in ca_classf_list_2:\n",
    "        df_test_mix[ca] = x_test[ca].values\n",
    "\n",
    "    test_pred2 = clf_final_classif_2.predict(df_test_mix)\n",
    "\n",
    "    df_mcnemar_test = pd.DataFrame()\n",
    "    df_mcnemar_test['model_pred_classif_1'] = test_pred\n",
    "    df_mcnemar_test['model_pred_classif_2'] = test_pred2\n",
    "    df_mcnemar_test['original_label'] = y_test.values\n",
    "\n",
    "    df_mcnemar_test['classf_1'] = np.where(df_mcnemar_test['model_pred_classif_1']==df_mcnemar_test['original_label'], 0, 1)\n",
    "    df_mcnemar_test['classf_2'] = np.where(df_mcnemar_test['model_pred_classif_2']==df_mcnemar_test['original_label'], 0, 1)\n",
    "\n",
    "    print(\"classf_1 acc: \" + str(1-sum(df_mcnemar_test['classf_1'])/len(df_mcnemar_test)))\n",
    "    print(\"classf_2 acc: \" + str(1-sum(df_mcnemar_test['classf_2'])/len(df_mcnemar_test)))\n",
    "\n",
    "    data_crosstab = pd.crosstab(df_mcnemar_test['classf_1'],  \n",
    "                                df_mcnemar_test['classf_2'], \n",
    "                                margins = False) \n",
    "    print(data_crosstab)\n",
    "\n",
    "    \n",
    "    count_contingence_table = np.where(data_crosstab>25, 1, 0).sum()\n",
    "    \n",
    "    if count_contingence_table==4:\n",
    "        result = mcnemar(data_crosstab, exact=False, correction=True)\n",
    "        print(\"Todos os termos maiores que 25\")\n",
    "    else:\n",
    "        print(\"Algum termo menor que 25\")\n",
    "        result = mcnemar(data_crosstab, exact=True)\n",
    "\n",
    "    print('statistic=%.3f, p-value=%.3f' % (result.statistic, result.pvalue))\n",
    "    # interpret the p-value\n",
    "    alpha = 0.05\n",
    "    if result.pvalue > alpha:\n",
    "        print('Same proportions of errors (fail to reject H0)')\n",
    "    else:\n",
    "        print('Different proportions of errors (reject H0)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.4923438138015517\n",
      "classf_2 acc: 0.5261331155573703\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         4822     1\n",
      "1          332  4641\n",
      "Algum termo menor que 25\n",
      "statistic=1.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.4923438138015517\n",
      "classf_2 acc: 0.5164352797060024\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         4821     2\n",
      "1          238  4735\n",
      "Algum termo menor que 25\n",
      "statistic=2.000, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_11, ca_list_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classf_1 acc: 0.5261331155573703\n",
      "classf_2 acc: 0.5164352797060024\n",
      "classf_2     0     1\n",
      "classf_1            \n",
      "0         4990   164\n",
      "1           69  4573\n",
      "Todos os termos maiores que 25\n",
      "statistic=37.923, p-value=0.000\n",
      "Different proportions of errors (reject H0)\n"
     ]
    }
   ],
   "source": [
    "test_mcnemar(20, ca_list_14, ca_list_34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
